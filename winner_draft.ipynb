{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "winner_draft.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bsekiewicz/dw_competition/blob/master/winner_draft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "4LeJwgXPrQiK",
        "colab_type": "code",
        "outputId": "f2b7a946-e68f-41d2-bf7f-7e480844ab40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        }
      },
      "source": [
        "!pip install scikit-plot\n",
        "!pip install eli5\n",
        "!pip instapgrade tables"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-plot\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/47/32520e259340c140a4ad27c1b97050dd3254fdc517b1d59974d47037510e/scikit_plot-0.3.7-py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.22.2.post1)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (3.2.1)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.14.1)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->scikit-plot) (1.18.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=1.4.0->scikit-plot) (1.12.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n",
            "Collecting eli5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/2f/c85c7d8f8548e460829971785347e14e45fa5c6617da374711dec8cb38cc/eli5-0.10.1-py2.py3-none-any.whl (105kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 36.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5) (2.11.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.22.2.post1)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (19.3.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.8.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (1.18.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5) (1.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5) (1.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->eli5) (0.14.1)\n",
            "Installing collected packages: eli5\n",
            "Successfully installed eli5-0.10.1\n",
            "Collecting tables\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/c3/8fd9e3bb21872f9d69eb93b3014c86479864cca94e625fd03713ccacec80/tables-3.6.1-cp36-cp36m-manylinux1_x86_64.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 43.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numexpr>=2.6.2 in /usr/local/lib/python3.6/dist-packages (from tables) (2.7.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.3 in /usr/local/lib/python3.6/dist-packages (from tables) (1.18.2)\n",
            "Installing collected packages: tables\n",
            "  Found existing installation: tables 3.4.4\n",
            "    Uninstalling tables-3.4.4:\n",
            "      Successfully uninstalled tables-3.4.4\n",
            "Successfully installed tables-3.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dorQlXR3dOCx",
        "colab_type": "code",
        "outputId": "26f1d74b-8b46-4ef7-e100-70d8f2648719",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd '/content/drive/My Drive/Colab Notebooks/competition/data/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/competition/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnW6T9hurd-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd # from pandas.core.common import flatten\n",
        "import numpy as np\n",
        "import string\n",
        "import regex\n",
        "import gc\n",
        "\n",
        "from collections import defaultdict \n",
        "\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, GroupKFold, train_test_split\n",
        "from sklearn.metrics import mean_squared_error as mse, precision_score, recall_score\n",
        "from sklearn import utils\n",
        "\n",
        "from scikitplot.metrics import plot_confusion_matrix, plot_calibration_curve\n",
        "from scikitplot.estimators import plot_learning_curve, plot_feature_importances\n",
        "\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "from hyperopt import hp, fmin, tpe, STATUS_OK\n",
        "\n",
        "#%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "RrDN4DRurQiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVqf8tZMdUTm",
        "colab_type": "text"
      },
      "source": [
        "## READ DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7MsLrMx9rQib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train = pd.read_hdf('../input/dw-competition/train_online_retail.h5').reset_index(drop=True)\n",
        "# test = pd.read_hdf('../input/dw-competition/test_online_retail.h5').reset_index(drop=True)\n",
        "\n",
        "train = pd.read_hdf('train_online_retail.h5').reset_index(drop=True)\n",
        "test = pd.read_hdf('test_online_retail.h5').reset_index(drop=True)\n",
        "\n",
        "df = pd.concat([train, test], sort=False)\n",
        "\n",
        "del test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoBqoBML4x9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# repair price total\n",
        "df['price_total'] = df['quantity'] * df['price_unit']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wc0hv0ixrQig",
        "colab_type": "code",
        "outputId": "34ff3807-9f61-44bf-d815-cb5d7d9b0efc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "gc.collect()  # release memory"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2576"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv0VgJ0Xdsb9",
        "colab_type": "text"
      },
      "source": [
        "## UTILS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1V-qNrC-yVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### FE\n",
        "\n",
        "# \n",
        "def get_feats(df, out=[]):\n",
        "    feats = df.select_dtypes([np.number, np.bool]).columns\n",
        "    black_list = ['is_test', 'is_canceled', 'is_canceled_pred', 'total_return', 'total_return_pred', 'invoice_price_total']\n",
        "    \n",
        "    return [x for x in feats if x not in black_list + out]\n",
        "\n",
        "# \n",
        "def group_by_key(df, group_key, agg_func, reversed=False):\n",
        "    df_temp = df[~df['is_canceled'].isnull()]\n",
        "    if reversed:\n",
        "        df_temp['is_canceled'] = df_temp['is_canceled'].map(lambda x: False if x else True)\n",
        "    dict_ = df_temp.groupby(group_key)['is_canceled'].agg(agg_func).to_dict()\n",
        "    if -1 in dict_: del dict_[-1]\n",
        "    \n",
        "    return df_temp[group_key].map(lambda x: dict_.get(x, -1))\n",
        "\n",
        "#\n",
        "def group_by_key_alt(df, group_key, group_key_alt, agg_func, reversed=False):\n",
        "    df_temp = df[~df['is_canceled'].isnull()]\n",
        "    if reversed:\n",
        "        df_temp['is_canceled'] = df_temp['is_canceled'].map(lambda x: False if x else True)\n",
        "    df_temp[group_key_alt] = df_temp[group_key_alt]*df_temp['is_canceled']\n",
        "    dict_ = df_temp.groupby(group_key)[group_key_alt].agg(agg_func).to_dict()\n",
        "    if -1 in dict_: del dict_[-1]\n",
        "    \n",
        "    return df_temp[group_key].map(lambda x: dict_.get(x, -1))\n",
        "\n",
        "#\n",
        "def aggregate_by(df, group_key, agg_key, agg_name, agg_fun, filtered=False):\n",
        "    if filtered:\n",
        "        df_temp = df[~df['is_canceled'].isnull()]\n",
        "    else:\n",
        "        df_temp = df\n",
        "    return pd.merge(df, df_temp.groupby(group_key).agg(agg_name=(agg_key, agg_fun)), how='left', on=[group_key]).rename(columns = {'agg_name': agg_name})\n",
        "\n",
        "# \n",
        "def prepare_categories(df, cats):\n",
        "    for c in cats:\n",
        "        df['cat_' + c] = df['description'].map(lambda x: c in str(x).lower())\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zoqqnaxxf5Sp",
        "colab_type": "code",
        "outputId": "d6a66c11-915e-4b70-e161-629b72cc87d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "train.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 520142 entries, 0 to 520141\n",
            "Data columns (total 11 columns):\n",
            " #   Column        Non-Null Count   Dtype         \n",
            "---  ------        --------------   -----         \n",
            " 0   invoice       520142 non-null  int32         \n",
            " 1   stock_code    520142 non-null  int16         \n",
            " 2   description   517903 non-null  object        \n",
            " 3   quantity      520142 non-null  int32         \n",
            " 4   invoice_date  520142 non-null  datetime64[ns]\n",
            " 5   price_unit    520142 non-null  float16       \n",
            " 6   price_total   520142 non-null  float32       \n",
            " 7   customer_id   520142 non-null  int16         \n",
            " 8   country       520142 non-null  object        \n",
            " 9   is_canceled   520142 non-null  bool          \n",
            " 10  is_test       520142 non-null  bool          \n",
            "dtypes: bool(2), datetime64[ns](1), float16(1), float32(1), int16(2), int32(2), object(2)\n",
            "memory usage: 21.8+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnHl26KEQIMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJdvPKlkQI0o",
        "colab_type": "text"
      },
      "source": [
        "## FE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj29pk1jQIQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df = aggregate_by_invoice(df, 'price_total', 'invoice_price_total')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXo2jGxbXcT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WQpWwesNrQir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# feature engineering\n",
        "\n",
        "\n",
        "\n",
        "#\n",
        "df['cnt_customer_cancel'] = df['customer_id'].map(group_to_dict(df, 'customer_id')).astype(np.int)\n",
        "df['cnt_customer_not_cancel'] = df['customer_id'].map(group_to_dict(df, 'customer_id', not_cancel=True)).astype(np.int)\n",
        "df['cnt_customer_orders'] = df['customer_id'].map(group_to_dict(df, 'customer_id', agg_func=np.size)).astype(np.int)\n",
        "\n",
        "df['cnt_product_cancel'] = df['stock_code'].map(group_to_dict(df, 'stock_code')).astype(np.int)\n",
        "df['cnt_product_not_cancel'] = df['stock_code'].map(group_to_dict(df, 'stock_code', not_cancel=True)).astype(np.int)\n",
        "df['cnt_product_orders'] = df['stock_code'].map(group_to_dict(df, 'stock_code', agg_func=np.size)).astype(np.int)\n",
        "df['cnt_product_stock_cancel'] = df['stock_code'].map(group_to_dict_alt(df, 'stock_code')).astype(np.int)\n",
        "df['cnt_product_stock_not_cancel'] = df['stock_code'].map(group_to_dict_alt(df, 'stock_code', not_cancel=True)).astype(np.int)\n",
        "\n",
        "# repair stock code\n",
        "df['description'] = df['description'].map(lambda x: str(x).lower().strip())\n",
        "df['description'] = df['description'].map(lambda x: regex.sub('|\\\\'.join(string.punctuation), ' ', x))\n",
        "df['description'] = df['description'].map(lambda x: regex.sub(' ([0-9]+[^ ]{0,} )+', ' ', x))\n",
        "df['description'] = df['description'].map(lambda x: regex.sub('^[0-9]+[^ ]{0,} ', ' ', x))\n",
        "df['description'] = df['description'].map(lambda x: regex.sub(' [0-9]+[^ ]{0,}$', ' ', x))\n",
        "df['description'] = df['description'].map(lambda x: regex.sub('[ ]+', ' ', x).strip())\n",
        "df['stock_code_2'] = df['description'].factorize()[0]\n",
        "\n",
        "df['cnt_product_cancel_2'] = df['stock_code_2'].map(group_to_dict(df, 'stock_code_2')).astype(np.int)\n",
        "df['cnt_product_not_cancel_2'] = df['stock_code_2'].map(group_to_dict(df, 'stock_code_2', not_cancel=True)).astype(np.int)\n",
        "df['cnt_product_orders_2'] = df['stock_code_2'].map(group_to_dict(df, 'stock_code_2', agg_func=np.size)).astype(np.int)\n",
        "df['cnt_product_stock_cancel_2'] = df['stock_code_2'].map(group_to_dict_alt(df, 'stock_code_2')).astype(np.int)\n",
        "df['cnt_product_stock_not_cancel_2'] = df['stock_code_2'].map(group_to_dict_alt(df, 'stock_code_2', not_cancel=True)).astype(np.int)\n",
        "\n",
        "# datetime\n",
        "df['invoice_date_y'] = df.invoice_date.dt.year\n",
        "df['invoice_date_m'] = df.invoice_date.dt.month\n",
        "df['invoice_date_d'] = df.invoice_date.dt.day\n",
        "df['invoice_date_h'] = df.invoice_date.dt.hour\n",
        "df['invoice_date_min'] = df.invoice_date.dt.minute\n",
        "df['invoice_date_dow'] = df.invoice_date.dt.dayofweek\n",
        "\n",
        "# countries\n",
        "df['country_europe'] = df['country'].map(lambda x: 0 if x in ['United Kingdom', 'France', 'EIRE', 'Netherlands', 'Poland', 'Germany', 'Spain', \n",
        "                                                              'Channel Islands', 'Italy', 'Cyprus', 'Greece', 'Norway', 'Portugal', 'Denmark', \n",
        "                                                              'Sweden', 'Finland', 'Belgium', 'Malta', 'Austria', 'Switzerland', 'Lithuania', \n",
        "                                                              'Iceland','Czech Republic'] else (-1 if x == 'Unspecified' else 1))\n",
        "df['country_cat'] = df['country'].factorize()[0]\n",
        "\n",
        "df['description_len'] = df['description'].map(lambda x: len(x))\n",
        "df['description_cnt_space'] = df['description'].map(lambda x: x.count(' '))\n",
        "\n",
        "# aggregations\n",
        "df = aggregate_by_invoice(df, 'price_unit', 'price_unit_min', agg_fun=np.min)\n",
        "df = aggregate_by_invoice(df, 'price_unit', 'price_unit_max', agg_fun=np.max)\n",
        "df = aggregate_by_invoice(df, 'price_unit', 'price_unit_mean', agg_fun=np.mean)\n",
        "df = aggregate_by_invoice(df, 'price_unit', 'price_unit_median', agg_fun=np.median)\n",
        "df = aggregate_by_invoice(df, 'price_unit', 'price_unit_sum', agg_fun=np.sum)\n",
        "df = aggregate_by_invoice(df, 'quantity', 'quantity_min', agg_fun=np.min)\n",
        "df = aggregate_by_invoice(df, 'quantity', 'quantity_max', agg_fun=np.max)\n",
        "df = aggregate_by_invoice(df, 'quantity', 'quantity_mean', agg_fun=np.mean)\n",
        "df = aggregate_by_invoice(df, 'quantity', 'quantity_median', agg_fun=np.median)\n",
        "df = aggregate_by_invoice(df, 'quantity', 'quantity_sum', agg_fun=np.sum)\n",
        "\n",
        "\n",
        "\n",
        "df = aggregate_by(df, 'quantity', 'quantity_stock', 'stock_code', agg_fun=np.sum)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfhUkVni-PAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RArF-fnBrQiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transformations\n",
        "\n",
        "df['price_total_log'] = df.price_total.map(lambda x: -1 if x<0 else np.log1p(x))\n",
        "df['price_unit_sum_log'] = df.price_unit_sum.map(lambda x: -1 if x<0 else np.log1p(x))\n",
        "df['quantity_sum_log'] = df.quantity_sum.map(lambda x: -1 if x<0 else np.log1p(x))\n",
        "df['quantity_log'] = df.quantity.map(lambda x: -1 if x<0 else np.log1p(x))\n",
        "df['quantity_stock_log'] = df.quantity_stock.map(lambda x: -1 if x<0 else np.log1p(x))\n",
        "df['invoice_price_total_log'] = df.invoice_price_total.map(lambda x: -1 if x<0 else np.log1p(x))\n",
        "df['cnt_product_stock_cancel_log'] = df.cnt_product_stock_cancel.map(lambda x: -1 if x<0 else np.log1p(x))\n",
        "df['cnt_product_stock_not_cancel_log'] = df.cnt_product_stock_not_cancel.map(lambda x: -1 if x<0 else np.log1p(x))\n",
        "df['cnt_product_stock_cancel_2_log'] = df.cnt_product_stock_cancel_2.map(lambda x: -1 if x<0 else np.log1p(x))\n",
        "df['cnt_product_stock_not_cancel_2_log'] = df.cnt_product_stock_not_cancel_2.map(lambda x: -1 if x<0 else np.log1p(x))\n",
        "df['cnt_customer_cancel_log'] = df.cnt_customer_cancel.map(lambda x: -1 if x<0 else np.log1p(x))\n",
        "\n",
        "out = ['cnt_customer_cancel','price_total','price_unit_sum','quantity_sum','quantity','quantity_stock','invoice_price_total','cnt_product_stock_cancel','cnt_product_stock_not_cancel','cnt_product_stock_cancel_2','cnt_product_stock_not_cancel_2',]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dnBZuAqmWw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# expensive or cheap\n",
        "tmp = df.copy()\n",
        "tmp = tmp[~tmp['is_canceled'].isnull()]\n",
        "dict_median = tmp.groupby('description')['price_unit'].agg(np.median).to_dict()\n",
        "dict_mean = tmp.groupby('description')['price_unit'].agg(np.mean).to_dict()\n",
        "\n",
        "if '' in dict_median: del dict_median['']\n",
        "if '' in dict_mean: del dict_mean['']\n",
        "\n",
        "t = list(dict_median.keys())\n",
        "for d in t:\n",
        "    if dict_median[d] == 0:\n",
        "        del dict_median[d]\n",
        "\n",
        "t = list(dict_mean.keys())\n",
        "for d in t:\n",
        "    if dict_mean[d] == 0:\n",
        "        del dict_mean[d]\n",
        "\n",
        "def ftmp(x, dict_):\n",
        "  v = (x['price_unit'] - dict_[x['description']])/dict_[x['description']]\n",
        "  if v <= -1:\n",
        "    return 0\n",
        "  elif v <= 0.25:\n",
        "    return 1\n",
        "  elif v >= 1:\n",
        "    return 4\n",
        "  elif v >= 0.25:\n",
        "    return 3\n",
        "  else:\n",
        "    return 2\n",
        "\n",
        "# df['price_cheap_exp_median'] = df.apply(lambda x: -1 if x['description'] not in dict_median else ftmp(x, dict_median), axis=1)\n",
        "# df['price_cheap_exp_mean'] = df.apply(lambda x: -1 if x['description'] not in dict_mean else ftmp(x, dict_mean), axis=1)\n",
        "df['price_cheap_exp_median'] = df.apply(lambda x: 0 if x['description'] not in dict_median else (x['price_unit'] - dict_median[x['description']])/dict_median[x['description']], axis=1)\n",
        "df['price_cheap_exp_mean'] = df.apply(lambda x: 0 if x['description'] not in dict_mean else (x['price_unit'] - dict_mean[x['description']])/dict_mean[x['description']], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QFPRFO_OrQi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # description tokenizer\n",
        "\n",
        "# desc = df[~df['is_canceled'].isnull()]['description']\n",
        "# desc = list(set(flatten([x.split(' ') for x in desc])))\n",
        "# desc = [x for x in desc if len(x) > 2]\n",
        "\n",
        "# def find_tokens(data, token):\n",
        "#     tmp = data.copy()\n",
        "#     tmp['is_token'] = tmp['description'].map(lambda x: token in x)\n",
        "\n",
        "#     x = tmp.groupby('is_token')['is_canceled'].agg(np.sum)\n",
        "#     y = tmp.groupby('is_token')['is_canceled'].agg(np.size)\n",
        "    \n",
        "#     freq = (x[1]+y[1])/(x[0]+y[0])\n",
        "#     diff = list(x/y)\n",
        "    \n",
        "# #     print('{}: freq = {} | diff = {}'.format(c, freq, diff[0]/diff[1]))\n",
        "    \n",
        "#     if diff[1] == 0:\n",
        "#         return freq, 100\n",
        "#     else:\n",
        "#         return freq, diff[0]/diff[1]\n",
        "    \n",
        "# train = df.copy()\n",
        "# train = train[ ~train['is_canceled'].isnull()][['invoice', 'is_canceled', 'description']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XvhTqYtzrQi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find_tokens(train, 'pink')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Z894Bsl3rQi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cat_desc = []\n",
        "# for c in sorted(desc):\n",
        "#     freq, diff = find_tokens(train, c)\n",
        "#     if freq > 0.02:\n",
        "#         if abs(diff-1) > 0.5:\n",
        "#             cat_desc += [c]\n",
        "#             print('{}: freq = {} | diff = {}'.format(c, freq, diff))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WVdNSovmrQjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_desc = [\n",
        "    'bottle',\n",
        "    'car',\n",
        "    'case',\n",
        "    'christmas',\n",
        "    'craft',\n",
        "    'decoration',\n",
        "    'door',\n",
        "    'felt',\n",
        "    'glass',\n",
        "    'hot',\n",
        "    'love',\n",
        "    'mat',\n",
        "    'metal',\n",
        "    'pack',\n",
        "    'paper',\n",
        "    'water',\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FZBvpxrGrQjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = prepare_categories(df, cat_desc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s23rI-DpHVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: \n",
        "# colors\n",
        "# size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwAm_X5lpHcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmSOcCCkpHfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "y92GrFn1rQjJ",
        "colab_type": "code",
        "outputId": "e4bfa38b-71e6-4409-943c-cd3006b2a5ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        }
      },
      "source": [
        "df.sample(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>invoice</th>\n",
              "      <th>stock_code</th>\n",
              "      <th>description</th>\n",
              "      <th>quantity</th>\n",
              "      <th>invoice_date</th>\n",
              "      <th>price_unit</th>\n",
              "      <th>price_total</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>country</th>\n",
              "      <th>is_canceled</th>\n",
              "      <th>is_test</th>\n",
              "      <th>cnt_customer_cancel</th>\n",
              "      <th>cnt_customer_not_cancel</th>\n",
              "      <th>cnt_customer_orders</th>\n",
              "      <th>cnt_product_cancel</th>\n",
              "      <th>cnt_product_not_cancel</th>\n",
              "      <th>cnt_product_orders</th>\n",
              "      <th>cnt_product_stock_cancel</th>\n",
              "      <th>cnt_product_stock_not_cancel</th>\n",
              "      <th>stock_code_2</th>\n",
              "      <th>cnt_product_cancel_2</th>\n",
              "      <th>cnt_product_not_cancel_2</th>\n",
              "      <th>cnt_product_orders_2</th>\n",
              "      <th>cnt_product_stock_cancel_2</th>\n",
              "      <th>cnt_product_stock_not_cancel_2</th>\n",
              "      <th>invoice_date_y</th>\n",
              "      <th>invoice_date_m</th>\n",
              "      <th>invoice_date_d</th>\n",
              "      <th>invoice_date_h</th>\n",
              "      <th>invoice_date_min</th>\n",
              "      <th>invoice_date_dow</th>\n",
              "      <th>country_europe</th>\n",
              "      <th>country_cat</th>\n",
              "      <th>description_len</th>\n",
              "      <th>description_cnt_space</th>\n",
              "      <th>price_unit_min</th>\n",
              "      <th>price_unit_max</th>\n",
              "      <th>price_unit_mean</th>\n",
              "      <th>price_unit_median</th>\n",
              "      <th>price_unit_sum</th>\n",
              "      <th>quantity_min</th>\n",
              "      <th>quantity_max</th>\n",
              "      <th>quantity_mean</th>\n",
              "      <th>quantity_median</th>\n",
              "      <th>quantity_sum</th>\n",
              "      <th>invoice_price_total</th>\n",
              "      <th>quantity_stock</th>\n",
              "      <th>price_total_log</th>\n",
              "      <th>price_unit_sum_log</th>\n",
              "      <th>quantity_sum_log</th>\n",
              "      <th>quantity_log</th>\n",
              "      <th>quantity_stock_log</th>\n",
              "      <th>invoice_price_total_log</th>\n",
              "      <th>cnt_product_stock_cancel_log</th>\n",
              "      <th>cnt_product_stock_not_cancel_log</th>\n",
              "      <th>cnt_product_stock_cancel_2_log</th>\n",
              "      <th>cnt_product_stock_not_cancel_2_log</th>\n",
              "      <th>cnt_customer_cancel_log</th>\n",
              "      <th>price_cheap_exp_median</th>\n",
              "      <th>price_cheap_exp_mean</th>\n",
              "      <th>cat_bottle</th>\n",
              "      <th>cat_car</th>\n",
              "      <th>cat_case</th>\n",
              "      <th>cat_christmas</th>\n",
              "      <th>cat_craft</th>\n",
              "      <th>cat_decoration</th>\n",
              "      <th>cat_door</th>\n",
              "      <th>cat_felt</th>\n",
              "      <th>cat_glass</th>\n",
              "      <th>cat_hot</th>\n",
              "      <th>cat_love</th>\n",
              "      <th>cat_mat</th>\n",
              "      <th>cat_metal</th>\n",
              "      <th>cat_pack</th>\n",
              "      <th>cat_paper</th>\n",
              "      <th>cat_water</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>237123</th>\n",
              "      <td>26748</td>\n",
              "      <td>4530</td>\n",
              "      <td>christmas lights reindeer</td>\n",
              "      <td>12</td>\n",
              "      <td>2010-11-23 12:04:00</td>\n",
              "      <td>8.500000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>2463</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>98</td>\n",
              "      <td>98</td>\n",
              "      <td>13</td>\n",
              "      <td>265</td>\n",
              "      <td>278</td>\n",
              "      <td>42</td>\n",
              "      <td>1165</td>\n",
              "      <td>4180</td>\n",
              "      <td>13</td>\n",
              "      <td>265</td>\n",
              "      <td>278</td>\n",
              "      <td>42</td>\n",
              "      <td>1165</td>\n",
              "      <td>2010</td>\n",
              "      <td>11</td>\n",
              "      <td>23</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>2</td>\n",
              "      <td>0.209961</td>\n",
              "      <td>9.953125</td>\n",
              "      <td>2.404297</td>\n",
              "      <td>1.450195</td>\n",
              "      <td>134.6250</td>\n",
              "      <td>2</td>\n",
              "      <td>48</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>12.0</td>\n",
              "      <td>840</td>\n",
              "      <td>1108.835938</td>\n",
              "      <td>1207.0</td>\n",
              "      <td>4.634729</td>\n",
              "      <td>4.909894</td>\n",
              "      <td>6.734592</td>\n",
              "      <td>2.564949</td>\n",
              "      <td>7.096721</td>\n",
              "      <td>7.011967</td>\n",
              "      <td>3.761200</td>\n",
              "      <td>7.061334</td>\n",
              "      <td>3.761200</td>\n",
              "      <td>7.061334</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.098592</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>607839</th>\n",
              "      <td>9972</td>\n",
              "      <td>680</td>\n",
              "      <td>lavender scented fabric heart</td>\n",
              "      <td>10</td>\n",
              "      <td>2010-04-28 14:59:00</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>1595</td>\n",
              "      <td>France</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>4</td>\n",
              "      <td>259</td>\n",
              "      <td>263</td>\n",
              "      <td>45</td>\n",
              "      <td>2775</td>\n",
              "      <td>480</td>\n",
              "      <td>4</td>\n",
              "      <td>259</td>\n",
              "      <td>263</td>\n",
              "      <td>45</td>\n",
              "      <td>2775</td>\n",
              "      <td>2010</td>\n",
              "      <td>4</td>\n",
              "      <td>28</td>\n",
              "      <td>14</td>\n",
              "      <td>59</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>3</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>5.187500</td>\n",
              "      <td>3.750000</td>\n",
              "      <td>57.0625</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>5.818182</td>\n",
              "      <td>6.0</td>\n",
              "      <td>64</td>\n",
              "      <td>249.671875</td>\n",
              "      <td>2820.0</td>\n",
              "      <td>2.602690</td>\n",
              "      <td>4.061520</td>\n",
              "      <td>4.174387</td>\n",
              "      <td>2.397895</td>\n",
              "      <td>7.944847</td>\n",
              "      <td>5.524145</td>\n",
              "      <td>3.828641</td>\n",
              "      <td>7.928766</td>\n",
              "      <td>3.828641</td>\n",
              "      <td>7.928766</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.306984</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14451</th>\n",
              "      <td>1398</td>\n",
              "      <td>13</td>\n",
              "      <td>love building block word</td>\n",
              "      <td>1</td>\n",
              "      <td>2009-12-13 15:54:00</td>\n",
              "      <td>5.949219</td>\n",
              "      <td>5.949219</td>\n",
              "      <td>831</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>241</td>\n",
              "      <td>243</td>\n",
              "      <td>11</td>\n",
              "      <td>879</td>\n",
              "      <td>890</td>\n",
              "      <td>29</td>\n",
              "      <td>2877</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>879</td>\n",
              "      <td>890</td>\n",
              "      <td>29</td>\n",
              "      <td>2877</td>\n",
              "      <td>2009</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>15</td>\n",
              "      <td>54</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "      <td>0.189941</td>\n",
              "      <td>7.949219</td>\n",
              "      <td>2.541016</td>\n",
              "      <td>1.800781</td>\n",
              "      <td>162.6250</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>2.390625</td>\n",
              "      <td>1.0</td>\n",
              "      <td>153</td>\n",
              "      <td>213.858398</td>\n",
              "      <td>2906.0</td>\n",
              "      <td>1.938629</td>\n",
              "      <td>5.097577</td>\n",
              "      <td>5.036953</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>7.974877</td>\n",
              "      <td>5.369979</td>\n",
              "      <td>3.401197</td>\n",
              "      <td>7.964851</td>\n",
              "      <td>3.401197</td>\n",
              "      <td>7.964851</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.108836</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216632</th>\n",
              "      <td>24874</td>\n",
              "      <td>3955</td>\n",
              "      <td>childs garden trowel pink</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-11-07 10:59:00</td>\n",
              "      <td>0.850098</td>\n",
              "      <td>0.850098</td>\n",
              "      <td>2116</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>225</td>\n",
              "      <td>226</td>\n",
              "      <td>1</td>\n",
              "      <td>180</td>\n",
              "      <td>181</td>\n",
              "      <td>2</td>\n",
              "      <td>1108</td>\n",
              "      <td>3379</td>\n",
              "      <td>1</td>\n",
              "      <td>180</td>\n",
              "      <td>181</td>\n",
              "      <td>2</td>\n",
              "      <td>1108</td>\n",
              "      <td>2010</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>59</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>0.290039</td>\n",
              "      <td>8.953125</td>\n",
              "      <td>2.316406</td>\n",
              "      <td>1.650391</td>\n",
              "      <td>113.5000</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>5.367347</td>\n",
              "      <td>3.0</td>\n",
              "      <td>263</td>\n",
              "      <td>517.296875</td>\n",
              "      <td>1110.0</td>\n",
              "      <td>0.615238</td>\n",
              "      <td>4.740575</td>\n",
              "      <td>5.575949</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>7.013016</td>\n",
              "      <td>6.250548</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>7.011214</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>7.011214</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.093229</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520512</th>\n",
              "      <td>60</td>\n",
              "      <td>562</td>\n",
              "      <td>door mat welcome puppies</td>\n",
              "      <td>2</td>\n",
              "      <td>2009-12-01 12:30:00</td>\n",
              "      <td>6.750000</td>\n",
              "      <td>13.500000</td>\n",
              "      <td>49</td>\n",
              "      <td>EIRE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>39</td>\n",
              "      <td>2003</td>\n",
              "      <td>2042</td>\n",
              "      <td>5</td>\n",
              "      <td>343</td>\n",
              "      <td>348</td>\n",
              "      <td>10</td>\n",
              "      <td>2179</td>\n",
              "      <td>429</td>\n",
              "      <td>1</td>\n",
              "      <td>146</td>\n",
              "      <td>147</td>\n",
              "      <td>2</td>\n",
              "      <td>630</td>\n",
              "      <td>2009</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "      <td>0.549805</td>\n",
              "      <td>14.953125</td>\n",
              "      <td>4.523438</td>\n",
              "      <td>3.449219</td>\n",
              "      <td>149.2500</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>6.424242</td>\n",
              "      <td>6.0</td>\n",
              "      <td>212</td>\n",
              "      <td>584.488281</td>\n",
              "      <td>2189.0</td>\n",
              "      <td>2.674149</td>\n",
              "      <td>5.012301</td>\n",
              "      <td>5.361292</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>7.691657</td>\n",
              "      <td>6.372446</td>\n",
              "      <td>2.397895</td>\n",
              "      <td>7.687080</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>6.447306</td>\n",
              "      <td>3.688879</td>\n",
              "      <td>-0.098592</td>\n",
              "      <td>-0.168431</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56699</th>\n",
              "      <td>6296</td>\n",
              "      <td>226</td>\n",
              "      <td>blue piece mini dots cutlery set</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-03-04 12:24:00</td>\n",
              "      <td>3.750000</td>\n",
              "      <td>3.750000</td>\n",
              "      <td>66</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>53</td>\n",
              "      <td>1236</td>\n",
              "      <td>1289</td>\n",
              "      <td>4</td>\n",
              "      <td>489</td>\n",
              "      <td>493</td>\n",
              "      <td>80</td>\n",
              "      <td>3929</td>\n",
              "      <td>161</td>\n",
              "      <td>2</td>\n",
              "      <td>257</td>\n",
              "      <td>259</td>\n",
              "      <td>73</td>\n",
              "      <td>1984</td>\n",
              "      <td>2010</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>5</td>\n",
              "      <td>0.099976</td>\n",
              "      <td>10.953125</td>\n",
              "      <td>2.759766</td>\n",
              "      <td>2.099609</td>\n",
              "      <td>165.6250</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>2.850000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>171</td>\n",
              "      <td>331.582642</td>\n",
              "      <td>4009.0</td>\n",
              "      <td>1.558145</td>\n",
              "      <td>5.115746</td>\n",
              "      <td>5.147494</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>8.296547</td>\n",
              "      <td>5.806888</td>\n",
              "      <td>4.394449</td>\n",
              "      <td>8.276395</td>\n",
              "      <td>4.304065</td>\n",
              "      <td>7.593374</td>\n",
              "      <td>3.988984</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.029323</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>948117</th>\n",
              "      <td>43634</td>\n",
              "      <td>3264</td>\n",
              "      <td>hot baths soap holder</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-08-22 13:30:00</td>\n",
              "      <td>1.690430</td>\n",
              "      <td>1.690430</td>\n",
              "      <td>3329</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>133</td>\n",
              "      <td>136</td>\n",
              "      <td>24</td>\n",
              "      <td>665</td>\n",
              "      <td>2823</td>\n",
              "      <td>3</td>\n",
              "      <td>132</td>\n",
              "      <td>135</td>\n",
              "      <td>24</td>\n",
              "      <td>585</td>\n",
              "      <td>2011</td>\n",
              "      <td>8</td>\n",
              "      <td>22</td>\n",
              "      <td>13</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>3</td>\n",
              "      <td>0.099976</td>\n",
              "      <td>5.949219</td>\n",
              "      <td>0.917480</td>\n",
              "      <td>0.419922</td>\n",
              "      <td>72.5000</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>7.962025</td>\n",
              "      <td>2.0</td>\n",
              "      <td>629</td>\n",
              "      <td>319.543213</td>\n",
              "      <td>689.0</td>\n",
              "      <td>0.989701</td>\n",
              "      <td>4.297285</td>\n",
              "      <td>6.445720</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>6.536692</td>\n",
              "      <td>5.770017</td>\n",
              "      <td>3.218876</td>\n",
              "      <td>6.501290</td>\n",
              "      <td>3.218876</td>\n",
              "      <td>6.373320</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.097497</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301169</th>\n",
              "      <td>32184</td>\n",
              "      <td>210</td>\n",
              "      <td>fawn blue hot water bottle</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-02-18 16:12:00</td>\n",
              "      <td>5.789062</td>\n",
              "      <td>5.789062</td>\n",
              "      <td>-1</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>81</td>\n",
              "      <td>83</td>\n",
              "      <td>6</td>\n",
              "      <td>559</td>\n",
              "      <td>565</td>\n",
              "      <td>428</td>\n",
              "      <td>4812</td>\n",
              "      <td>145</td>\n",
              "      <td>6</td>\n",
              "      <td>559</td>\n",
              "      <td>565</td>\n",
              "      <td>428</td>\n",
              "      <td>4812</td>\n",
              "      <td>2011</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>16</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>4</td>\n",
              "      <td>0.419922</td>\n",
              "      <td>149.000000</td>\n",
              "      <td>5.484375</td>\n",
              "      <td>3.289062</td>\n",
              "      <td>1157.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>2.511848</td>\n",
              "      <td>1.0</td>\n",
              "      <td>530</td>\n",
              "      <td>1735.984863</td>\n",
              "      <td>5240.0</td>\n",
              "      <td>1.915313</td>\n",
              "      <td>7.054450</td>\n",
              "      <td>6.274762</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>8.564268</td>\n",
              "      <td>7.459906</td>\n",
              "      <td>6.061457</td>\n",
              "      <td>8.479076</td>\n",
              "      <td>6.061457</td>\n",
              "      <td>8.479076</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.962914</td>\n",
              "      <td>0.602162</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88752</th>\n",
              "      <td>9832</td>\n",
              "      <td>805</td>\n",
              "      <td>small glass heart trinket pot</td>\n",
              "      <td>8</td>\n",
              "      <td>2010-04-27 11:00:00</td>\n",
              "      <td>2.099609</td>\n",
              "      <td>16.796875</td>\n",
              "      <td>2474</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>36</td>\n",
              "      <td>503</td>\n",
              "      <td>539</td>\n",
              "      <td>109</td>\n",
              "      <td>6319</td>\n",
              "      <td>679</td>\n",
              "      <td>36</td>\n",
              "      <td>502</td>\n",
              "      <td>538</td>\n",
              "      <td>109</td>\n",
              "      <td>5173</td>\n",
              "      <td>2010</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>4</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>2.099609</td>\n",
              "      <td>1.666992</td>\n",
              "      <td>1.650391</td>\n",
              "      <td>5.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>8.0</td>\n",
              "      <td>25</td>\n",
              "      <td>38.447266</td>\n",
              "      <td>6428.0</td>\n",
              "      <td>2.879023</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>3.258097</td>\n",
              "      <td>2.197225</td>\n",
              "      <td>8.768574</td>\n",
              "      <td>3.674965</td>\n",
              "      <td>4.700480</td>\n",
              "      <td>8.751474</td>\n",
              "      <td>4.700480</td>\n",
              "      <td>8.551401</td>\n",
              "      <td>1.609438</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.229391</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415064</th>\n",
              "      <td>44511</td>\n",
              "      <td>973</td>\n",
              "      <td>owl doorstop</td>\n",
              "      <td>3</td>\n",
              "      <td>2011-09-06 09:34:00</td>\n",
              "      <td>4.949219</td>\n",
              "      <td>14.847656</td>\n",
              "      <td>26</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "      <td>158</td>\n",
              "      <td>164</td>\n",
              "      <td>0</td>\n",
              "      <td>280</td>\n",
              "      <td>280</td>\n",
              "      <td>0</td>\n",
              "      <td>767</td>\n",
              "      <td>658</td>\n",
              "      <td>0</td>\n",
              "      <td>279</td>\n",
              "      <td>279</td>\n",
              "      <td>0</td>\n",
              "      <td>734</td>\n",
              "      <td>2011</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0.290039</td>\n",
              "      <td>6.250000</td>\n",
              "      <td>2.455078</td>\n",
              "      <td>1.669922</td>\n",
              "      <td>73.6875</td>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "      <td>10.866667</td>\n",
              "      <td>12.0</td>\n",
              "      <td>326</td>\n",
              "      <td>556.275391</td>\n",
              "      <td>767.0</td>\n",
              "      <td>2.763022</td>\n",
              "      <td>4.313313</td>\n",
              "      <td>5.789960</td>\n",
              "      <td>1.386294</td>\n",
              "      <td>6.643790</td>\n",
              "      <td>6.323060</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.643790</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.599870</td>\n",
              "      <td>1.945910</td>\n",
              "      <td>-0.402922</td>\n",
              "      <td>-0.256019</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        invoice  stock_code  ... cat_paper  cat_water\n",
              "237123    26748        4530  ...     False      False\n",
              "607839     9972         680  ...     False      False\n",
              "14451      1398          13  ...     False      False\n",
              "216632    24874        3955  ...     False      False\n",
              "520512       60         562  ...     False      False\n",
              "56699      6296         226  ...     False      False\n",
              "948117    43634        3264  ...     False      False\n",
              "301169    32184         210  ...     False       True\n",
              "88752      9832         805  ...     False      False\n",
              "415064    44511         973  ...     False      False\n",
              "\n",
              "[10 rows x 76 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "juAXrnJ5rQjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare to train\n",
        "train = df[~df['is_canceled'].isnull()].copy()\n",
        "test = df[df['is_canceled'].isnull()].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NLKqgyuErQjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['is_canceled'] = train['is_canceled'].astype('bool')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "C_V_XpUWrQjU",
        "colab_type": "code",
        "outputId": "99631757-efa4-4cb9-87c9-fd7c425d6cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# release memory\n",
        "del df\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bwP7VQw5rQjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train[~train.invoice.isin([53588, 53587, 30479])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "e0itjdUQrQjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train[train.description != 'amazon fee']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6tqQOCJirQjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train[train.description != 'adjust bad debt']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LK53hCsjrQjq",
        "colab_type": "code",
        "outputId": "289e5e5a-fa8b-4684-8960-601a13596d1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        }
      },
      "source": [
        "train.sort_values(by='invoice_price_total', ascending=False).head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>invoice</th>\n",
              "      <th>stock_code</th>\n",
              "      <th>description</th>\n",
              "      <th>quantity</th>\n",
              "      <th>invoice_date</th>\n",
              "      <th>price_unit</th>\n",
              "      <th>price_total</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>country</th>\n",
              "      <th>is_canceled</th>\n",
              "      <th>is_test</th>\n",
              "      <th>cnt_customer_cancel</th>\n",
              "      <th>cnt_customer_not_cancel</th>\n",
              "      <th>cnt_customer_orders</th>\n",
              "      <th>cnt_product_cancel</th>\n",
              "      <th>cnt_product_not_cancel</th>\n",
              "      <th>cnt_product_orders</th>\n",
              "      <th>cnt_product_stock_cancel</th>\n",
              "      <th>cnt_product_stock_not_cancel</th>\n",
              "      <th>stock_code_2</th>\n",
              "      <th>cnt_product_cancel_2</th>\n",
              "      <th>cnt_product_not_cancel_2</th>\n",
              "      <th>cnt_product_orders_2</th>\n",
              "      <th>cnt_product_stock_cancel_2</th>\n",
              "      <th>cnt_product_stock_not_cancel_2</th>\n",
              "      <th>invoice_date_y</th>\n",
              "      <th>invoice_date_m</th>\n",
              "      <th>invoice_date_d</th>\n",
              "      <th>invoice_date_h</th>\n",
              "      <th>invoice_date_min</th>\n",
              "      <th>invoice_date_dow</th>\n",
              "      <th>country_europe</th>\n",
              "      <th>country_cat</th>\n",
              "      <th>description_len</th>\n",
              "      <th>description_cnt_space</th>\n",
              "      <th>price_unit_min</th>\n",
              "      <th>price_unit_max</th>\n",
              "      <th>price_unit_mean</th>\n",
              "      <th>price_unit_median</th>\n",
              "      <th>price_unit_sum</th>\n",
              "      <th>quantity_min</th>\n",
              "      <th>quantity_max</th>\n",
              "      <th>quantity_mean</th>\n",
              "      <th>quantity_median</th>\n",
              "      <th>quantity_sum</th>\n",
              "      <th>invoice_price_total</th>\n",
              "      <th>quantity_stock</th>\n",
              "      <th>price_total_log</th>\n",
              "      <th>price_unit_sum_log</th>\n",
              "      <th>quantity_sum_log</th>\n",
              "      <th>quantity_log</th>\n",
              "      <th>quantity_stock_log</th>\n",
              "      <th>invoice_price_total_log</th>\n",
              "      <th>cnt_product_stock_cancel_log</th>\n",
              "      <th>cnt_product_stock_not_cancel_log</th>\n",
              "      <th>cnt_product_stock_cancel_2_log</th>\n",
              "      <th>cnt_product_stock_not_cancel_2_log</th>\n",
              "      <th>cnt_customer_cancel_log</th>\n",
              "      <th>price_cheap_exp_median</th>\n",
              "      <th>price_cheap_exp_mean</th>\n",
              "      <th>cat_bottle</th>\n",
              "      <th>cat_car</th>\n",
              "      <th>cat_case</th>\n",
              "      <th>cat_christmas</th>\n",
              "      <th>cat_craft</th>\n",
              "      <th>cat_decoration</th>\n",
              "      <th>cat_door</th>\n",
              "      <th>cat_felt</th>\n",
              "      <th>cat_glass</th>\n",
              "      <th>cat_hot</th>\n",
              "      <th>cat_love</th>\n",
              "      <th>cat_mat</th>\n",
              "      <th>cat_metal</th>\n",
              "      <th>cat_pack</th>\n",
              "      <th>cat_paper</th>\n",
              "      <th>cat_water</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>228272</th>\n",
              "      <td>25892</td>\n",
              "      <td>4433</td>\n",
              "      <td>alarm clock bakelike orange</td>\n",
              "      <td>6</td>\n",
              "      <td>2010-11-15 16:02:00</td>\n",
              "      <td>8.953125</td>\n",
              "      <td>53.718750</td>\n",
              "      <td>-1</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>81</td>\n",
              "      <td>83</td>\n",
              "      <td>10</td>\n",
              "      <td>312</td>\n",
              "      <td>322</td>\n",
              "      <td>16</td>\n",
              "      <td>1581</td>\n",
              "      <td>3990</td>\n",
              "      <td>10</td>\n",
              "      <td>312</td>\n",
              "      <td>322</td>\n",
              "      <td>16</td>\n",
              "      <td>1581</td>\n",
              "      <td>2010</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.953125</td>\n",
              "      <td>5.097656</td>\n",
              "      <td>3.949219</td>\n",
              "      <td>565.5</td>\n",
              "      <td>4</td>\n",
              "      <td>902</td>\n",
              "      <td>120.603604</td>\n",
              "      <td>73.0</td>\n",
              "      <td>13387</td>\n",
              "      <td>49840.712891</td>\n",
              "      <td>1597.0</td>\n",
              "      <td>4.002206</td>\n",
              "      <td>6.339477</td>\n",
              "      <td>9.502114</td>\n",
              "      <td>1.945910</td>\n",
              "      <td>7.376508</td>\n",
              "      <td>10.816608</td>\n",
              "      <td>2.833213</td>\n",
              "      <td>7.366445</td>\n",
              "      <td>2.833213</td>\n",
              "      <td>7.366445</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>1.387500</td>\n",
              "      <td>0.994778</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228294</th>\n",
              "      <td>25892</td>\n",
              "      <td>4298</td>\n",
              "      <td>christmas musical zinc star</td>\n",
              "      <td>21</td>\n",
              "      <td>2010-11-15 16:02:00</td>\n",
              "      <td>1.950195</td>\n",
              "      <td>40.954102</td>\n",
              "      <td>-1</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>81</td>\n",
              "      <td>83</td>\n",
              "      <td>1</td>\n",
              "      <td>84</td>\n",
              "      <td>85</td>\n",
              "      <td>24</td>\n",
              "      <td>1169</td>\n",
              "      <td>3771</td>\n",
              "      <td>1</td>\n",
              "      <td>84</td>\n",
              "      <td>85</td>\n",
              "      <td>24</td>\n",
              "      <td>1169</td>\n",
              "      <td>2010</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.953125</td>\n",
              "      <td>5.097656</td>\n",
              "      <td>3.949219</td>\n",
              "      <td>565.5</td>\n",
              "      <td>4</td>\n",
              "      <td>902</td>\n",
              "      <td>120.603604</td>\n",
              "      <td>73.0</td>\n",
              "      <td>13387</td>\n",
              "      <td>49840.712891</td>\n",
              "      <td>1193.0</td>\n",
              "      <td>3.736576</td>\n",
              "      <td>6.339477</td>\n",
              "      <td>9.502114</td>\n",
              "      <td>3.091042</td>\n",
              "      <td>7.085064</td>\n",
              "      <td>10.816608</td>\n",
              "      <td>3.218876</td>\n",
              "      <td>7.064759</td>\n",
              "      <td>3.218876</td>\n",
              "      <td>7.064759</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>1.349412</td>\n",
              "      <td>1.545570</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228266</th>\n",
              "      <td>25892</td>\n",
              "      <td>4448</td>\n",
              "      <td>polkadot pen</td>\n",
              "      <td>76</td>\n",
              "      <td>2010-11-15 16:02:00</td>\n",
              "      <td>1.950195</td>\n",
              "      <td>148.214844</td>\n",
              "      <td>-1</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>81</td>\n",
              "      <td>83</td>\n",
              "      <td>0</td>\n",
              "      <td>157</td>\n",
              "      <td>157</td>\n",
              "      <td>0</td>\n",
              "      <td>6832</td>\n",
              "      <td>4083</td>\n",
              "      <td>0</td>\n",
              "      <td>142</td>\n",
              "      <td>142</td>\n",
              "      <td>0</td>\n",
              "      <td>6083</td>\n",
              "      <td>2010</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.953125</td>\n",
              "      <td>5.097656</td>\n",
              "      <td>3.949219</td>\n",
              "      <td>565.5</td>\n",
              "      <td>4</td>\n",
              "      <td>902</td>\n",
              "      <td>120.603604</td>\n",
              "      <td>73.0</td>\n",
              "      <td>13387</td>\n",
              "      <td>49840.712891</td>\n",
              "      <td>6832.0</td>\n",
              "      <td>5.005387</td>\n",
              "      <td>6.339477</td>\n",
              "      <td>9.502114</td>\n",
              "      <td>4.343805</td>\n",
              "      <td>8.829519</td>\n",
              "      <td>10.816608</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.829519</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.713418</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>1.294084</td>\n",
              "      <td>0.792639</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228267</th>\n",
              "      <td>25892</td>\n",
              "      <td>4388</td>\n",
              "      <td>ribbon reel snowy village</td>\n",
              "      <td>109</td>\n",
              "      <td>2010-11-15 16:02:00</td>\n",
              "      <td>3.949219</td>\n",
              "      <td>430.464844</td>\n",
              "      <td>-1</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>81</td>\n",
              "      <td>83</td>\n",
              "      <td>2</td>\n",
              "      <td>259</td>\n",
              "      <td>261</td>\n",
              "      <td>20</td>\n",
              "      <td>2444</td>\n",
              "      <td>3900</td>\n",
              "      <td>2</td>\n",
              "      <td>259</td>\n",
              "      <td>261</td>\n",
              "      <td>20</td>\n",
              "      <td>2444</td>\n",
              "      <td>2010</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.953125</td>\n",
              "      <td>5.097656</td>\n",
              "      <td>3.949219</td>\n",
              "      <td>565.5</td>\n",
              "      <td>4</td>\n",
              "      <td>902</td>\n",
              "      <td>120.603604</td>\n",
              "      <td>73.0</td>\n",
              "      <td>13387</td>\n",
              "      <td>49840.712891</td>\n",
              "      <td>2464.0</td>\n",
              "      <td>6.067186</td>\n",
              "      <td>6.339477</td>\n",
              "      <td>9.502114</td>\n",
              "      <td>4.700480</td>\n",
              "      <td>7.809947</td>\n",
              "      <td>10.816608</td>\n",
              "      <td>3.044522</td>\n",
              "      <td>7.801800</td>\n",
              "      <td>3.044522</td>\n",
              "      <td>7.801800</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>1.392899</td>\n",
              "      <td>0.872222</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228268</th>\n",
              "      <td>25892</td>\n",
              "      <td>4385</td>\n",
              "      <td>set of ribbons vintage christmas</td>\n",
              "      <td>130</td>\n",
              "      <td>2010-11-15 16:02:00</td>\n",
              "      <td>5.949219</td>\n",
              "      <td>773.398438</td>\n",
              "      <td>-1</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>81</td>\n",
              "      <td>83</td>\n",
              "      <td>3</td>\n",
              "      <td>395</td>\n",
              "      <td>398</td>\n",
              "      <td>24</td>\n",
              "      <td>5987</td>\n",
              "      <td>3912</td>\n",
              "      <td>3</td>\n",
              "      <td>386</td>\n",
              "      <td>389</td>\n",
              "      <td>24</td>\n",
              "      <td>4776</td>\n",
              "      <td>2010</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.953125</td>\n",
              "      <td>5.097656</td>\n",
              "      <td>3.949219</td>\n",
              "      <td>565.5</td>\n",
              "      <td>4</td>\n",
              "      <td>902</td>\n",
              "      <td>120.603604</td>\n",
              "      <td>73.0</td>\n",
              "      <td>13387</td>\n",
              "      <td>49840.712891</td>\n",
              "      <td>6011.0</td>\n",
              "      <td>6.652087</td>\n",
              "      <td>6.339477</td>\n",
              "      <td>9.502114</td>\n",
              "      <td>4.875197</td>\n",
              "      <td>8.701513</td>\n",
              "      <td>10.816608</td>\n",
              "      <td>3.218876</td>\n",
              "      <td>8.697513</td>\n",
              "      <td>3.218876</td>\n",
              "      <td>8.471568</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>1.058108</td>\n",
              "      <td>0.844942</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228269</th>\n",
              "      <td>25892</td>\n",
              "      <td>4379</td>\n",
              "      <td>vintage christmas stickers</td>\n",
              "      <td>51</td>\n",
              "      <td>2010-11-15 16:02:00</td>\n",
              "      <td>2.949219</td>\n",
              "      <td>150.410156</td>\n",
              "      <td>-1</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>81</td>\n",
              "      <td>83</td>\n",
              "      <td>0</td>\n",
              "      <td>168</td>\n",
              "      <td>168</td>\n",
              "      <td>0</td>\n",
              "      <td>1605</td>\n",
              "      <td>3892</td>\n",
              "      <td>0</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>0</td>\n",
              "      <td>1285</td>\n",
              "      <td>2010</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.953125</td>\n",
              "      <td>5.097656</td>\n",
              "      <td>3.949219</td>\n",
              "      <td>565.5</td>\n",
              "      <td>4</td>\n",
              "      <td>902</td>\n",
              "      <td>120.603604</td>\n",
              "      <td>73.0</td>\n",
              "      <td>13387</td>\n",
              "      <td>49840.712891</td>\n",
              "      <td>1605.0</td>\n",
              "      <td>5.019992</td>\n",
              "      <td>6.339477</td>\n",
              "      <td>9.502114</td>\n",
              "      <td>3.951244</td>\n",
              "      <td>7.381502</td>\n",
              "      <td>10.816608</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.381502</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.159292</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>1.359375</td>\n",
              "      <td>0.910183</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228270</th>\n",
              "      <td>25892</td>\n",
              "      <td>4397</td>\n",
              "      <td>christmas stamps stickers</td>\n",
              "      <td>68</td>\n",
              "      <td>2010-11-15 16:02:00</td>\n",
              "      <td>2.949219</td>\n",
              "      <td>200.546875</td>\n",
              "      <td>-1</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>81</td>\n",
              "      <td>83</td>\n",
              "      <td>2</td>\n",
              "      <td>133</td>\n",
              "      <td>135</td>\n",
              "      <td>34</td>\n",
              "      <td>1293</td>\n",
              "      <td>3946</td>\n",
              "      <td>2</td>\n",
              "      <td>119</td>\n",
              "      <td>121</td>\n",
              "      <td>34</td>\n",
              "      <td>893</td>\n",
              "      <td>2010</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.953125</td>\n",
              "      <td>5.097656</td>\n",
              "      <td>3.949219</td>\n",
              "      <td>565.5</td>\n",
              "      <td>4</td>\n",
              "      <td>902</td>\n",
              "      <td>120.603604</td>\n",
              "      <td>73.0</td>\n",
              "      <td>13387</td>\n",
              "      <td>49840.712891</td>\n",
              "      <td>1327.0</td>\n",
              "      <td>5.306022</td>\n",
              "      <td>6.339477</td>\n",
              "      <td>9.502114</td>\n",
              "      <td>4.234107</td>\n",
              "      <td>7.191429</td>\n",
              "      <td>10.816608</td>\n",
              "      <td>3.555348</td>\n",
              "      <td>7.165493</td>\n",
              "      <td>3.555348</td>\n",
              "      <td>6.795706</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>1.359375</td>\n",
              "      <td>1.046070</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228271</th>\n",
              "      <td>25892</td>\n",
              "      <td>4435</td>\n",
              "      <td>alarm clock bakelike ivory</td>\n",
              "      <td>20</td>\n",
              "      <td>2010-11-15 16:02:00</td>\n",
              "      <td>8.953125</td>\n",
              "      <td>179.062500</td>\n",
              "      <td>-1</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>81</td>\n",
              "      <td>83</td>\n",
              "      <td>9</td>\n",
              "      <td>401</td>\n",
              "      <td>410</td>\n",
              "      <td>10</td>\n",
              "      <td>1753</td>\n",
              "      <td>3995</td>\n",
              "      <td>9</td>\n",
              "      <td>401</td>\n",
              "      <td>410</td>\n",
              "      <td>10</td>\n",
              "      <td>1753</td>\n",
              "      <td>2010</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.953125</td>\n",
              "      <td>5.097656</td>\n",
              "      <td>3.949219</td>\n",
              "      <td>565.5</td>\n",
              "      <td>4</td>\n",
              "      <td>902</td>\n",
              "      <td>120.603604</td>\n",
              "      <td>73.0</td>\n",
              "      <td>13387</td>\n",
              "      <td>49840.712891</td>\n",
              "      <td>1763.0</td>\n",
              "      <td>5.193304</td>\n",
              "      <td>6.339477</td>\n",
              "      <td>9.502114</td>\n",
              "      <td>3.044522</td>\n",
              "      <td>7.475339</td>\n",
              "      <td>10.816608</td>\n",
              "      <td>2.397895</td>\n",
              "      <td>7.469654</td>\n",
              "      <td>2.397895</td>\n",
              "      <td>7.469654</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>1.387500</td>\n",
              "      <td>1.070461</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228273</th>\n",
              "      <td>25892</td>\n",
              "      <td>4436</td>\n",
              "      <td>alarm clock bakelike pink</td>\n",
              "      <td>20</td>\n",
              "      <td>2010-11-15 16:02:00</td>\n",
              "      <td>8.953125</td>\n",
              "      <td>179.062500</td>\n",
              "      <td>-1</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>81</td>\n",
              "      <td>83</td>\n",
              "      <td>11</td>\n",
              "      <td>477</td>\n",
              "      <td>488</td>\n",
              "      <td>19</td>\n",
              "      <td>3654</td>\n",
              "      <td>3996</td>\n",
              "      <td>11</td>\n",
              "      <td>477</td>\n",
              "      <td>488</td>\n",
              "      <td>19</td>\n",
              "      <td>3654</td>\n",
              "      <td>2010</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.953125</td>\n",
              "      <td>5.097656</td>\n",
              "      <td>3.949219</td>\n",
              "      <td>565.5</td>\n",
              "      <td>4</td>\n",
              "      <td>902</td>\n",
              "      <td>120.603604</td>\n",
              "      <td>73.0</td>\n",
              "      <td>13387</td>\n",
              "      <td>49840.712891</td>\n",
              "      <td>3673.0</td>\n",
              "      <td>5.193304</td>\n",
              "      <td>6.339477</td>\n",
              "      <td>9.502114</td>\n",
              "      <td>3.044522</td>\n",
              "      <td>8.209036</td>\n",
              "      <td>10.816608</td>\n",
              "      <td>2.995732</td>\n",
              "      <td>8.203851</td>\n",
              "      <td>2.995732</td>\n",
              "      <td>8.203851</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>1.387500</td>\n",
              "      <td>1.022948</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228274</th>\n",
              "      <td>25892</td>\n",
              "      <td>4432</td>\n",
              "      <td>alarm clock bakelike red</td>\n",
              "      <td>30</td>\n",
              "      <td>2010-11-15 16:02:00</td>\n",
              "      <td>8.953125</td>\n",
              "      <td>268.593750</td>\n",
              "      <td>-1</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>81</td>\n",
              "      <td>83</td>\n",
              "      <td>17</td>\n",
              "      <td>700</td>\n",
              "      <td>717</td>\n",
              "      <td>33</td>\n",
              "      <td>4776</td>\n",
              "      <td>3989</td>\n",
              "      <td>17</td>\n",
              "      <td>700</td>\n",
              "      <td>717</td>\n",
              "      <td>33</td>\n",
              "      <td>4776</td>\n",
              "      <td>2010</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.953125</td>\n",
              "      <td>5.097656</td>\n",
              "      <td>3.949219</td>\n",
              "      <td>565.5</td>\n",
              "      <td>4</td>\n",
              "      <td>902</td>\n",
              "      <td>120.603604</td>\n",
              "      <td>73.0</td>\n",
              "      <td>13387</td>\n",
              "      <td>49840.712891</td>\n",
              "      <td>4809.0</td>\n",
              "      <td>5.596916</td>\n",
              "      <td>6.339477</td>\n",
              "      <td>9.502114</td>\n",
              "      <td>3.433987</td>\n",
              "      <td>8.478452</td>\n",
              "      <td>10.816608</td>\n",
              "      <td>3.526361</td>\n",
              "      <td>8.471568</td>\n",
              "      <td>3.526361</td>\n",
              "      <td>8.471568</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>1.387500</td>\n",
              "      <td>1.102752</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        invoice  stock_code  ... cat_paper  cat_water\n",
              "228272    25892        4433  ...     False      False\n",
              "228294    25892        4298  ...     False      False\n",
              "228266    25892        4448  ...     False      False\n",
              "228267    25892        4388  ...     False      False\n",
              "228268    25892        4385  ...     False      False\n",
              "228269    25892        4379  ...     False      False\n",
              "228270    25892        4397  ...     False      False\n",
              "228271    25892        4435  ...     False      False\n",
              "228273    25892        4436  ...     False      False\n",
              "228274    25892        4432  ...     False      False\n",
              "\n",
              "[10 rows x 76 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VouTi-P_rQjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# + valid set\n",
        "\n",
        "train, valid = train_test_split(train, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Aw2IdYNbrQjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "O_sZriVcrQjz",
        "colab_type": "code",
        "outputId": "3ed05342-1320-4522-e099-b4128f0a0663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# dummy model #0 - the worst case ever\n",
        "\n",
        "orders_train = train[['invoice', 'invoice_price_total']].drop_duplicates()\n",
        "orders_test = test[['invoice', 'invoice_price_total']].drop_duplicates()\n",
        "\n",
        "mse_train = sum(orders_train.invoice_price_total * orders_train.invoice_price_total) / (len(orders_train)-1)\n",
        "mse_test = sum(orders_test.invoice_price_total * orders_test.invoice_price_total) / (len(orders_test)-1)\n",
        "\n",
        "print('MSE train vs MSE test: {} vs {} (ratio {})'.format(mse_train, mse_test, round(mse_train/mse_test*100)/100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE train vs MSE test: 1266020.118589018 vs 1894213.902757539 (ratio 0.67)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DDmAdUn-rQj2",
        "colab_type": "code",
        "outputId": "a1ff1db7-6d93-4a77-cac0-9f3e3b588ff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# dummy model #1\n",
        "\n",
        "feats = ['invoice']\n",
        "\n",
        "orders_train = train[['invoice', 'is_canceled', 'invoice_price_total']].drop_duplicates()\n",
        "orders_train['total_return'] = orders_train['invoice_price_total'] * orders_train['is_canceled'] \n",
        "\n",
        "X = orders_train[feats].values\n",
        "y = orders_train['total_return'].values\n",
        "\n",
        "model = DummyRegressor(strategy='mean')\n",
        "model.fit(X, y)\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "mse(y, y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115350.79594281623"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4p6gVUjDrQj4",
        "colab_type": "code",
        "outputId": "7c38d816-2656-409e-9073-be251e0854e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "115680 / 263376 # vs submission"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4392199744851467"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8AoP6nbvrQj8",
        "colab_type": "code",
        "outputId": "8f95cf77-c09e-4cb5-f3bb-bd7505195057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# dummy model #2\n",
        "\n",
        "orders_train = train[['invoice', 'is_canceled', 'invoice_price_total']].drop_duplicates()\n",
        "orders_train['total_return'] = orders_train['invoice_price_total'] * orders_train['is_canceled'] \n",
        "\n",
        "sum(orders_train.total_return * orders_train.total_return) / (len(orders_train)-1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115705.54950087005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rzVgR_J7rQj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model #1\n",
        "\n",
        "def run_model(model, feats, data, data_to_predict=None, data_valid=None, threshold=0.02, scenario={'opt': '3', 'fun': np.mean}):\n",
        "#     data = train.copy()\n",
        "#     data_test = test.copy()\n",
        "\n",
        "    X_invoice = data[['invoice', 'is_canceled']].drop_duplicates().reset_index(drop=True)\n",
        "    \n",
        "    scores = []\n",
        "    ratio_upper = 0\n",
        "    ratio_lower = 0\n",
        "    preditions = []\n",
        "    valid_preditions = []\n",
        "    \n",
        "    skf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
        "    for train_invoice_index, test_invoice_index in skf.split(X_invoice[['invoice']], X_invoice['is_canceled'] == True):\n",
        "        train_invoice_list = list(X_invoice.iloc[train_invoice_index].invoice)\n",
        "        test_invoice_list = list(X_invoice.iloc[test_invoice_index].invoice)\n",
        "\n",
        "        df_train, df_test = data[data.invoice.isin(train_invoice_list)], data[data.invoice.isin(test_invoice_list)]\n",
        "\n",
        "        X_train, X_test = df_train[feats], df_test[feats]\n",
        "        y_train, y_test = df_train['is_canceled'], df_test['is_canceled']\n",
        "\n",
        "        # class weights\n",
        "        class_weights = list(class_weight.compute_class_weight('balanced',\n",
        "                                                               np.unique(df_train['is_canceled']),\n",
        "                                                               df_train['is_canceled']))\n",
        "\n",
        "        w_array = np.ones(y_train.shape[0], dtype = 'float')\n",
        "        for i, val in enumerate(y_train):\n",
        "            w_array[i] = class_weights[val-1]\n",
        "\n",
        "        # model fit\n",
        "        model.fit(X_train.values, y_train, eval_metric=[\"auc\",\"error\",\"logloss\"], sample_weight=w_array)\n",
        "\n",
        "#         tmp = df_train.copy()[['invoice', 'invoice_price_total', 'is_canceled']].drop_duplicates()\n",
        "#         mse_score_max = sum(tmp.invoice_price_total * tmp.invoice_price_total) / (len(tmp)-1)\n",
        "#         orders_train = df_train.copy()    \n",
        "#         orders_train['is_canceled_pred_1'] = model.predict(X_train.values) # 0,1\n",
        "#         orders_train['is_canceled_pred_2'] = model.predict_proba(X_train.values)[:, 1] # probrabilities\n",
        "#         orders_train['is_canceled_pred_3'] = orders_train['is_canceled_pred_2']*orders_train['price_total']/orders_train['invoice_price_total'] # probabilities weightedby price\n",
        "#         tmp = pd.merge(tmp, orders_train.groupby('invoice').agg(is_canceled_pred = ('is_canceled_pred_' + str(scenario['opt']), scenario['fun'])).reset_index(), how='left', on=['invoice'])            \n",
        "#         tmp['total_return'] = tmp['is_canceled'] * tmp['invoice_price_total']\n",
        "#         tmp['total_return_pred'] = (tmp['is_canceled_pred'] > threshold) * tmp['invoice_price_total']        \n",
        "#         mse_score = mse(tmp['total_return'], tmp['total_return_pred'])\n",
        "#         print('train set ratio: {}'.format(res_mse/res_mse_base))\n",
        "    \n",
        "        tmp = df_test.copy()[['invoice', 'invoice_price_total', 'is_canceled']].drop_duplicates()\n",
        "        mse_score_max = sum(tmp.invoice_price_total * tmp.invoice_price_total) / (len(tmp)-1)\n",
        "        ratio_lower += mse_score_max\n",
        "    \n",
        "        orders_test = df_test.copy()    \n",
        "        orders_test['is_canceled_pred_1'] = model.predict(X_test.values) # 0,1\n",
        "        orders_test['is_canceled_pred_2'] = model.predict_proba(X_test.values)[:, 1] # probrabilities\n",
        "        orders_test['is_canceled_pred_3'] = orders_test['is_canceled_pred_2']*orders_test['price_total']/orders_test['invoice_price_total'] # probabilities weightedby price\n",
        "        \n",
        "        p_ratio_pred = sum(orders_test['is_canceled_pred_' + str(scenario['opt'])] > threshold)/len(orders_test)\n",
        "\n",
        "        tmp = pd.merge(tmp, orders_test.groupby('invoice').agg(is_canceled_pred = ('is_canceled_pred_' + str(scenario['opt']), scenario['fun'])).reset_index(), how='left', on=['invoice'])            \n",
        "        tmp['total_return'] = tmp['is_canceled'] * tmp['invoice_price_total']\n",
        "        tmp['total_return_pred'] = (tmp['is_canceled_pred'] > threshold) * tmp['invoice_price_total']        \n",
        "        mse_score = mse(tmp['total_return'], tmp['total_return_pred'])\n",
        "        ratio_upper += mse_score\n",
        "\n",
        "        fp_ratio_pred = sum(tmp['is_canceled_pred'] > threshold)/len(tmp)\n",
        "        \n",
        "        print('mse {} / mse base {} : ratio {} mean ratio {} : p_ratio_pred {} fp_ratio_pred {}'.format(mse_score, mse_score_max, mse_score/mse_score_max, ratio_upper/ratio_lower, p_ratio_pred, fp_ratio_pred))\n",
        "        \n",
        "        scores += [mse_score/mse_score_max]\n",
        "\n",
        "        if data_valid is not None:\n",
        "            data_valid['is_canceled_pred_1'] = model.predict(data_valid[feats].values) # 0,1\n",
        "            data_valid['is_canceled_pred_2'] = model.predict_proba(data_valid[feats].values)[:, 1] # probrabilities\n",
        "            data_valid['is_canceled_pred_3'] = data_valid['is_canceled_pred_2']*data_valid['price_total']/data_valid['invoice_price_total'] # probabilities weightedby price\n",
        "            valid_preditions += [data_valid.copy()[['invoice', 'is_canceled_pred_' + str(scenario['opt'])]].rename(columns={'is_canceled_pred_' + str(scenario['opt']): 'is_canceled_pred'})]\n",
        "\n",
        "        if data_to_predict is not None:\n",
        "            data_to_predict['is_canceled_pred_1'] = model.predict(data_to_predict[feats].values) # 0,1\n",
        "            data_to_predict['is_canceled_pred_2'] = model.predict_proba(data_to_predict[feats].values)[:, 1] # probrabilities\n",
        "            data_to_predict['is_canceled_pred_3'] = data_to_predict['is_canceled_pred_2']*data_to_predict['price_total']/data_to_predict['invoice_price_total'] # probabilities weightedby price\n",
        "            preditions += [data_to_predict.copy()[['invoice', 'is_canceled_pred_' + str(scenario['opt'])]].rename(columns={'is_canceled_pred_' + str(scenario['opt']): 'is_canceled_pred'})]\n",
        "\n",
        "    scores_validation = None\n",
        "    if data_valid is not None:\n",
        "      w1 = 1/scores[0]\n",
        "      w2 = 1/scores[1]\n",
        "      w3 = 1/scores[2]\n",
        "      w4 = 1/scores[3]\n",
        "      w5 = 1/scores[4]\n",
        "      w = w1+w2+w3+w4+w5\n",
        "      w1 = w1/w\n",
        "      w2 = w2/w\n",
        "      w3 = w3/w\n",
        "      w4 = w4/w\n",
        "      w5 = w5/w\n",
        "\n",
        "      tmp = data_valid.copy()[['invoice', 'invoice_price_total']].drop_duplicates()\n",
        "      mse_score_max = sum(tmp.invoice_price_total * tmp.invoice_price_total) / (len(tmp)-1)\n",
        "\n",
        "      tmp = data_valid.copy()[['invoice', 'description', 'invoice_price_total', 'is_canceled']]\n",
        "      is_false = list(tmp[(tmp.description == 'adjust bad debt')].invoice.unique()) + [30477]\n",
        "      is_true  = list(tmp[(tmp.description == 'amazon fee')].invoice.unique())\n",
        "   \n",
        "      tmp['is_canceled_pred'] = valid_preditions[0]['is_canceled_pred']*w1 + valid_preditions[1]['is_canceled_pred']*w2 + valid_preditions[2]['is_canceled_pred']*w3 + valid_preditions[3]['is_canceled_pred']*w4 + valid_preditions[4]['is_canceled_pred']*w5\n",
        "\n",
        "      p_ratio = sum(tmp['is_canceled'] > threshold)/len(tmp)\n",
        "      p_ratio_pred = sum(tmp['is_canceled_pred'] > threshold)/len(tmp)\n",
        "\n",
        "      tmp = tmp.groupby('invoice').agg(is_canceled_pred = ('is_canceled_pred', scenario['fun']),\n",
        "                                       is_canceled = ('is_canceled', np.mean),\n",
        "                                       invoice_price_total = ('invoice_price_total', np.mean)).reset_index()\n",
        "        \n",
        "      tmp['total_return'] = tmp['is_canceled'] * tmp['invoice_price_total']\n",
        "\n",
        "      fp_ratio = sum(tmp['is_canceled'] > threshold)/len(tmp)\n",
        "      fp_ratio_pred = sum(tmp['is_canceled_pred'] > threshold)/len(tmp)\n",
        "\n",
        "      tmp['is_canceled_pred'] = tmp.apply(lambda x: 0 if x['invoice'] in is_false else x['is_canceled_pred'], axis=1)\n",
        "      tmp['is_canceled_pred'] = tmp.apply(lambda x: 1 if x['invoice'] in is_true else x['is_canceled_pred'], axis=1)\n",
        "\n",
        "      tmp['total_return_pred'] = (tmp['is_canceled_pred'] > threshold) * tmp['invoice_price_total']        \n",
        "      mse_score = mse(tmp['total_return'], tmp['total_return_pred'])\n",
        "  \n",
        "      scores_validation = mse_score/mse_score_max\n",
        "\n",
        "      print('VALIDATION: mse {} / mse base {} : ratio {}'.format(mse_score, mse_score_max, scores_validation))\n",
        "      print('VALIDATION: p {} p_pred {} : fp {} fp_pred {}'.format(p_ratio, p_ratio_pred, fp_ratio, fp_ratio_pred))\n",
        "\n",
        "    submission = None\n",
        "    if data_to_predict is not None:\n",
        "      w1 = 1/scores[0]\n",
        "      w2 = 1/scores[1]\n",
        "      w3 = 1/scores[2]\n",
        "      w4 = 1/scores[3]\n",
        "      w5 = 1/scores[4]\n",
        "      w = w1+w2+w3+w4+w5\n",
        "      w1 = w1/w\n",
        "      w2 = w2/w\n",
        "      w3 = w3/w\n",
        "      w4 = w4/w\n",
        "      w5 = w5/w\n",
        "\n",
        "      tmp = data_to_predict.copy()[['invoice', 'invoice_price_total']].drop_duplicates()\n",
        "      mse_score_max = sum(tmp.invoice_price_total * tmp.invoice_price_total) / (len(tmp)-1)\n",
        "  \n",
        "      tmp = data_to_predict.copy()[['invoice', 'description', 'invoice_price_total']].drop_duplicates()\n",
        "      is_false = list(tmp[(tmp.description == 'adjust bad debt')].invoice.unique()) + [30477]\n",
        "      is_true  = list(tmp[(tmp.description == 'amazon fee')].invoice.unique())\n",
        "   \n",
        "      tmp['is_canceled_pred'] = preditions[0]['is_canceled_pred']*w1 + preditions[1]['is_canceled_pred']*w2 + preditions[2]['is_canceled_pred']*w3 + preditions[3]['is_canceled_pred']*w4 + preditions[4]['is_canceled_pred']*w5\n",
        "      p_ratio_pred = sum(tmp['is_canceled_pred'] > threshold)/len(tmp)\n",
        "      \n",
        "      tmp = tmp.groupby('invoice').agg(is_canceled_pred = ('is_canceled_pred', scenario['fun']),\n",
        "                                       invoice_price_total = ('invoice_price_total', np.mean)).reset_index()\n",
        "\n",
        "      fp_ratio_pred = sum(tmp['is_canceled_pred'] > threshold)/len(tmp)\n",
        "\n",
        "      tmp['is_canceled_pred'] = tmp.apply(lambda x: 0 if x['invoice'] in is_false else x['is_canceled_pred'], axis=1)\n",
        "      tmp['is_canceled_pred'] = tmp.apply(lambda x: 1 if x['invoice'] in is_true else x['is_canceled_pred'], axis=1)\n",
        "\n",
        "      tmp['total_return_pred'] = (tmp['is_canceled_pred'] > threshold) * tmp['invoice_price_total']        \n",
        "\n",
        "      submission = tmp.copy()\n",
        "      submission = submission.rename(columns={'total_return_pred': 'total_return'})\n",
        "\n",
        "      print('SUBMISSION: ratio * mse base: {} * {} = {} : p_pred {} fp_pred {}'.format(ratio_upper/ratio_lower, mse_score_max, ratio_upper/ratio_lower*mse_score_max, p_ratio_pred, fp_ratio_pred))\n",
        "\n",
        "    return scores, ratio_upper/ratio_lower, scores_validation, submission"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Gksmo2zsrQkC",
        "colab_type": "code",
        "outputId": "3d2404e6-c933-4149-a401-082a1caf7cc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "best = {'model': {'colsample_bytree': 0.15000000000000002, 'eta': 0.025, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.9, 'learning_rate': 0.28, 'max_depth': 10, 'min_child_weight': 10.0, 'n_estimators': 120, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.79, 'tree_method': 'gpu_hist'}, 'threshold': 0.015}\n",
        "\n",
        "model = xgb.XGBClassifier(**best['model'])\n",
        "\n",
        "threshold = best['threshold']\n",
        "\n",
        "feats = get_feats(train)\n",
        "\n",
        "scenario={\n",
        "    'opt': '3', \n",
        "    'fun': np.mean\n",
        "}\n",
        "\n",
        "### run\n",
        "\n",
        "scores, ratio, scores_validation, submission = run_model(model, feats, train, data_to_predict=test, data_valid=valid, threshold=threshold, scenario=scenario)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mse 36004.667162455706 / mse base 1413979.3221247324 : ratio 0.025463361874594373 mean ratio 0.025463361874594373 : p_ratio_pred 0.016177882839624732 fp_ratio_pred 0.15557749259624876\n",
            "mse 45406.13812185953 / mse base 1833752.1432910159 : ratio 0.024761327907908866 mean ratio 0.02506697556470965 : p_ratio_pred 0.016381200163812 fp_ratio_pred 0.15932872655478775\n",
            "mse 49650.052176874764 / mse base 1317959.2996501562 : ratio 0.037671916113080316 mean ratio 0.028705592254296742 : p_ratio_pred 0.01536034942975006 fp_ratio_pred 0.15205371248025276\n",
            "mse 39685.31819380141 / mse base 825381.321367404 : ratio 0.048081192494221936 mean ratio 0.03167202606781609 : p_ratio_pred 0.01557938037092637 fp_ratio_pred 0.1542259083728278\n",
            "mse 25867.05001852385 / mse base 939887.3627723363 : ratio 0.0275214361242449 mean ratio 0.03105583399340595 : p_ratio_pred 0.01587919083321545 fp_ratio_pred 0.15165876777251186\n",
            "VALIDATION: mse 6654.778736752044 / mse base 1585230.1557363835 : ratio 0.004197988987700473\n",
            "VALIDATION: p 0.019322649798602234 p_pred 0.019284196764177152 : fp 0.07657706481682203 fp_pred 0.08432690223282029\n",
            "SUBMISSION: ratio * mse base: 0.03105583399340595 * 1894213.902757539 = 58826.39251203973 : p_pred 0.013055386955753437 fp_pred 0.1471619303348997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIs_NVZx0kni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission[['invoice', 'total_return']].to_csv('submission_20200408_d_2.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8hHwObswTXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mse 40737.27563160426 / mse base 1657410.707915358 : ratio 0.02457886596065401 mean ratio 0.02457886596065401 : p_ratio_pred 0.01587264039362256 fp_ratio_pred 0.15596691610870422\n",
        "mse 25525.10806073305 / mse base 1105614.3590499812 : ratio 0.02308680947547204 mean ratio 0.02398182502380046 : p_ratio_pred 0.016861771313704622 fp_ratio_pred 0.15714848365498227\n",
        "mse 26226.63689472856 / mse base 1365189.0073213824 : ratio 0.01921099331600059 mean ratio 0.02240412413763844 : p_ratio_pred 0.01577784398430905 fp_ratio_pred 0.1553761323355652\n",
        "mse 89764.2486250246 / mse base 915765.1153817634 : ratio 0.09802103958459234 mean ratio 0.03613283527921713 : p_ratio_pred 0.01548913043478261 fp_ratio_pred 0.15675462780622293\n",
        "mse 25436.30419200403 / mse base 1293528.7919238745 : ratio 0.019664273691328074 mean ratio 0.03277148904701032 : p_ratio_pred 0.016006945718233734 fp_ratio_pred 0.1612839700669555\n",
        "VALIDATION: mse 8535.446055506041 / mse base 1612787.2127774516 : ratio 0.005292357223496815\n",
        "VALIDATION: p 0.019139997885083106 p_pred 0.018880439902713823 : fp 0.07529168029658707 fp_pred 0.08243375858684986\n",
        "SUBMISSION: ratio * mse base: 0.03277148904701032 * 1894213.902757539 = 62076.21016691336 : p_pred 0.013055386955753437 fp_pred 0.14663981502200343"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUH9llCv6kWe",
        "colab_type": "text"
      },
      "source": [
        "# ELI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A-x62oG8Gej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9lmlafi2rQkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feats = get_feats(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6vTJwe4KrQkq",
        "colab_type": "code",
        "outputId": "e363bd17-2483-4c0a-d29b-dd3c3967e99f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        }
      },
      "source": [
        "best = {'model': {'colsample_bytree': 0.15, 'eta': 0.025, 'eval_metric': ['auc', 'error', 'logloss'], 'gamma': 0.9, 'learning_rate': 0.28, 'max_depth': 10, 'min_child_weight': 10.0, 'n_estimators': 120, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.79, 'tree_method': 'gpu_hist'}, 'threshold': 0.015}\n",
        "\n",
        "model = xgb.XGBClassifier(**best['model'])\n",
        "\n",
        "feats = get_feats(train, out)\n",
        "\n",
        "X = train[feats].values\n",
        "y = train['is_canceled'].values\n",
        "\n",
        "# class weights\n",
        "class_weights = list(class_weight.compute_class_weight('balanced',\n",
        "                                                       np.unique(train['is_canceled']),\n",
        "                                                       train['is_canceled']))\n",
        "w_array = np.ones(y.shape[0], dtype = 'float')\n",
        "for i, val in enumerate(y):\n",
        "    w_array[i] = class_weights[val-1]\n",
        "\n",
        "# model fit\n",
        "model.fit(X, y, eval_metric=[\"auc\",\"error\",\"logloss\"], sample_weight=w_array)\n",
        "\n",
        "imp = PermutationImportance(model, random_state=0).fit(X, y)\n",
        "eli5.show_weights(imp, feature_names=feats, top=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0091\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                price_unit_sum_log\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 81.14%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0083\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                invoice_price_total_log\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 82.08%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0077\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cnt_customer_cancel_log\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 90.01%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0034\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quantity_sum_log\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 92.88%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0021\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cnt_product_stock_cancel_2_log\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 93.01%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0020\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                price_unit_min\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 93.10%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0020\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cnt_customer_orders\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 93.29%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0019\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                price_unit_max\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 93.71%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0017\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quantity_mean\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 93.86%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0017\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quantity_max\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 93.96%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0016\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cnt_product_cancel\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 94.13%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0016\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cnt_customer_not_cancel\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 94.75%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0013\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                price_unit_mean\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 94.84%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0013\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cnt_product_cancel_2\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.40%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0011\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                invoice\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.40%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0011\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                invoice_date_min\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.54%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0011\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quantity_median\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.92%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0009\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                customer_id\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.05%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0009\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                invoice_date_d\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.14%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0009\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                invoice_date_h\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.42%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                price_unit_median\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.27%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                invoice_date_dow\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.28%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                country_cat\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.51%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                invoice_date_m\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.05%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                price_total_log\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.24%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cnt_product_not_cancel_2\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.31%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cnt_product_stock_cancel_log\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.34%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quantity_min\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.64%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0002\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                country_europe\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.73%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0002\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                price_unit\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.85%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0002\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                price_cheap_exp_mean\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.89%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cnt_product_stock_not_cancel_2_log\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.01%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                stock_code\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.02%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cnt_product_orders_2\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.15%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cnt_product_not_cancel\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.21%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cnt_product_orders\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.28%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                description_len\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.33%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                invoice_date_y\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.36%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                stock_code_2\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.39%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                description_cnt_space\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.47%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quantity_stock_log\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.52%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                price_cheap_exp_median\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.71%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quantity_log\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.72%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cnt_product_stock_not_cancel_log\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.85%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cat_glass\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.89%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cat_car\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.96%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cat_metal\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.97%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cat_door\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.98%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cat_christmas\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.98%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cat_mat\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 99.98%); border: none;\">\n",
              "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
              "                    <i>&hellip; 10 more &hellip;</i>\n",
              "                </td>\n",
              "            </tr>\n",
              "        \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xHt5kdlJrQks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feats_eli = ['cnt_customer_cancel','quantity_sum','price_unit_sum_log','quantity_sum_log','invoice_price_total_log','price_unit_sum','cnt_customer_not_cancel','quantity_max','customer_id','price_unit_max','cnt_product_cancel_2','quantity_mean','quantity_median','price_unit_mean','invoice_date_d','cnt_customer_orders','cnt_product_stock_cancel_2','price_unit_min','invoice_date_min','cnt_product_stock_cancel_2_log','invoice','price_unit_median','cnt_product_cancel','cnt_product_stock_cancel','cnt_product_stock_cancel_log','invoice_date_h','invoice_date_dow','country_cat','invoice_date_m','price_total_log','quantity_min','stock_code','cnt_product_stock_not_cancel_2_log','cnt_product_orders','cnt_product_not_cancel_2','description_len','description_cnt_space','cnt_product_orders_2','cnt_product_stock_not_cancel_log','quantity_stock','cnt_product_stock_not_cancel',]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLLR8tyi6qAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "0.0095 ± 0.0001 \tcnt_customer_cancel\n",
        "0.0065 ± 0.0001 \tquantity_sum\n",
        "0.0043 ± 0.0000 \tquantity_sum_log\n",
        "0.0040 ± 0.0001 \tprice_unit_sum_log\n",
        "0.0040 ± 0.0000 \tprice_unit_sum\n",
        "0.0033 ± 0.0001 \tinvoice_price_total_log\n",
        "0.0023 ± 0.0001 \tcnt_customer_not_cancel\n",
        "0.0016 ± 0.0001 \tcustomer_id\n",
        "0.0016 ± 0.0001 \tcnt_product_cancel_2\n",
        "0.0016 ± 0.0001 \tquantity_max\n",
        "0.0013 ± 0.0001 \tprice_unit_max\n",
        "0.0013 ± 0.0000 \tquantity_median\n",
        "0.0011 ± 0.0001 \tprice_unit_min\n",
        "0.0011 ± 0.0000 \tinvoice_date_d\n",
        "0.0011 ± 0.0001 \tprice_unit_mean\n",
        "0.0010 ± 0.0001 \tquantity_mean\n",
        "0.0009 ± 0.0001 \tcnt_product_cancel\n",
        "0.0008 ± 0.0001 \tinvoice\n",
        "0.0008 ± 0.0000 \tcnt_customer_orders\n",
        "0.0008 ± 0.0001 \tinvoice_date_min\n",
        "0.0007 ± 0.0000 \tcnt_product_stock_cancel_2\n",
        "0.0007 ± 0.0001 \tcnt_product_stock_cancel\n",
        "0.0006 ± 0.0000 \tprice_unit_median\n",
        "0.0006 ± 0.0001 \tcnt_product_stock_cancel_2_log\n",
        "0.0006 ± 0.0001 \tcnt_product_stock_cancel_log\n",
        "0.0006 ± 0.0001 \tinvoice_date_m\n",
        "0.0005 ± 0.0001 \tinvoice_date_h\n",
        "0.0004 ± 0.0000 \tinvoice_date_dow\n",
        "0.0003 ± 0.0000 \tcountry_cat\n",
        "0.0002 ± 0.0000 \tquantity_min\n",
        "0.0002 ± 0.0000 \tcnt_product_orders\n",
        "0.0002 ± 0.0001 \tcnt_product_stock_not_cancel_2_log\n",
        "0.0001 ± 0.0000 \tstock_code\n",
        "0.0001 ± 0.0000 \tcnt_product_stock_not_cancel_log\n",
        "0.0001 ± 0.0000 \tcnt_product_stock_not_cancel\n",
        "0.0001 ± 0.0000 \tcnt_product_stock_not_cancel_2\n",
        "0.0001 ± 0.0000 \tquantity\n",
        "0.0001 ± 0.0000 \tcnt_product_orders_2\n",
        "0.0001 ± 0.0000 \tinvoice_date_y\n",
        "0.0001 ± 0.0000 \tstock_code_2\n",
        "0.0001 ± 0.0000 \tcnt_product_not_cancel\n",
        "0.0001 ± 0.0000 \tquantity_log\n",
        "0.0001 ± 0.0000 \tprice_cheap_exp_mean\n",
        "0.0001 ± 0.0000 \tdescription_len\n",
        "0.0001 ± 0.0000 \tdescription_cnt_space\n",
        "0.0001 ± 0.0000 \tprice_total\n",
        "0.0001 ± 0.0000 \tquantity_stock\n",
        "0.0000 ± 0.0000 \tquantity_stock_log\n",
        "0.0000 ± 0.0000 \tcnt_product_not_cancel_2\n",
        "0.0000 ± 0.0000 \tprice_unit "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofGD8hjx86MM",
        "colab_type": "text"
      },
      "source": [
        "# HYPER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0CzwEgkfrQkw",
        "colab_type": "code",
        "outputId": "aa3e04eb-3a72-48e6-ca11-f8f2aad59ce2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# hyperopt\n",
        "# feats = get_feats(train)\n",
        "feats = feats_eli\n",
        "\n",
        "def obj_func(params):\n",
        "  print(\"Training with params: \")\n",
        "  print(params)\n",
        "\n",
        "  scores, ratio, scores_validation, submission = run_model(xgb.XGBClassifier(**params['model']), feats, train, data_valid=valid, threshold=params['threshold'], scenario={'opt': '3', 'fun': np.mean})\n",
        "  print('MSE: {} ({}) - {} + {}'.format(np.abs(np.mean(scores)), np.std(scores), ratio, scores_validation))\n",
        "  print('---------------- \\n')\n",
        "\n",
        "  return {'loss': scores_validation, 'status': STATUS_OK}\n",
        "\n",
        "# space\n",
        "f_params = {'model': {\n",
        "    'max_depth' : hp.choice('max_depth', range(1, 16, 1)),\n",
        "    'learning_rate' : hp.quniform('learning_rate', 0.01, 0.3, 0.02),\n",
        "    'n_estimators' : hp.choice('n_estimators', range(50, 200, 10)),\n",
        "    'gamma' : hp.quniform('gamma', 0, 1, 0.1),\n",
        "    'eta': hp.quniform('eta', 0.025, 0.5, 0.025),\n",
        "    'min_child_weight' : hp.quniform('min_child_weight', 1, 80, 5),\n",
        "    'subsample' : hp.quniform('subsample', 0.1, 1, 0.01),\n",
        "    'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1, 0.05),\n",
        "    'seed': 0,\n",
        "    'tree_method': 'gpu_hist',\n",
        "    'objective': 'binary:logistic', \n",
        "    'eval_metric': [\"auc\",\"error\",\"logloss\"],\n",
        "},\n",
        "    'threshold': hp.quniform('threshold', 0.001, 0.030, 0.001)\n",
        "}\n",
        "\n",
        "# run\n",
        "best = fmin(obj_func, f_params, algo=tpe.suggest, max_evals=30, return_argmin=False)\n",
        "\n",
        "print('---------------- \\n')\n",
        "\n",
        "best"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.75, 'eta': 0.1, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.4, 'learning_rate': 0.1, 'max_depth': 15, 'min_child_weight': 15.0, 'n_estimators': 140, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.64, 'tree_method': 'gpu_hist'}, 'threshold': 0.016}\n",
            "mse 24101.0416742197 / mse base 1657410.707915358 : ratio 0.014541381661841244 mean ratio 0.014541381661841244 : p_ratio_pred 0.0152221223447036 fp_ratio_pred 0.15222528554549036\n",
            "mse 36040.9476778284 / mse base 1105614.3590499812 : ratio 0.032598118306637426 mean ratio 0.021766718684931335 : p_ratio_pred 0.016554333688069054 fp_ratio_pred 0.15714848365498227\n",
            "mse 20640.380649689065 / mse base 1365189.0073213824 : ratio 0.015119064495096732 mean ratio 0.019568357780887332 : p_ratio_pred 0.01596404985351805 fp_ratio_pred 0.15242221346987003\n",
            "mse 90149.01504585512 / mse base 915765.1153817634 : ratio 0.09844119800116416 mean ratio 0.03388820187793573 : p_ratio_pred 0.015311909262759925 fp_ratio_pred 0.15380070894052777\n",
            "mse 25140.711963956917 / mse base 1293528.7919238745 : ratio 0.019435757534677647 mean ratio 0.030938358986063827 : p_ratio_pred 0.015835748437824815 fp_ratio_pred 0.15931469082315872\n",
            "VALIDATION: mse 16864.248092764978 / mse base 1612787.2127774516 : ratio 0.010456585939643158\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.017236572681041694 : fp 0.07529168029658707 fp_pred 0.07676371169992367\n",
            "MSE: 0.03602710399988344 (0.03187893420657239) - 0.030938358986063827 + 0.010456585939643158\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.9500000000000001, 'eta': 0.42500000000000004, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.8, 'learning_rate': 0.12, 'max_depth': 9, 'min_child_weight': 25.0, 'n_estimators': 120, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.92, 'tree_method': 'gpu_hist'}, 'threshold': 0.015}\n",
            "mse 23616.589856819497 / mse base 1657410.707915358 : ratio 0.014249087292626306 mean ratio 0.014249087292626306 : p_ratio_pred 0.015162984340256423 fp_ratio_pred 0.151831429696731\n",
            "mse 36743.31370475859 / mse base 1105614.3590499812 : ratio 0.03323339047109603 mean ratio 0.02184558666630992 : p_ratio_pred 0.016447912971502898 fp_ratio_pred 0.15478534856242615\n",
            "mse 21955.085040102716 / mse base 1365189.0073213824 : ratio 0.01608208454826374 mean ratio 0.01993961241360849 : p_ratio_pred 0.015678534187397588 fp_ratio_pred 0.1492713666797952\n",
            "mse 90040.29580591292 / mse base 915765.1153817634 : ratio 0.09832247843201254 mean ratio 0.03417049871272799 : p_ratio_pred 0.015347353497164462 fp_ratio_pred 0.15301299724300907\n",
            "mse 25142.192224293347 / mse base 1293528.7919238745 : ratio 0.019436901892921292 mean ratio 0.031163270674455852 : p_ratio_pred 0.015860205192168946 fp_ratio_pred 0.15852697912564\n",
            "VALIDATION: mse 25180.77587490201 / mse base 1612787.2127774516 : ratio 0.015613204070199125\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.01692894840564106 : fp 0.07529168029658707 fp_pred 0.07610947552066295\n",
            "MSE: 0.03626478852738398 (0.03173501744075127) - 0.031163270674455852 + 0.015613204070199125\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.55, 'eta': 0.07500000000000001, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.1, 'learning_rate': 0.2, 'max_depth': 12, 'min_child_weight': 25.0, 'n_estimators': 80, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.26, 'tree_method': 'gpu_hist'}, 'threshold': 0.012}\n",
            "mse 20004.392527667733 / mse base 1657410.707915358 : ratio 0.012069665311157947 mean ratio 0.012069665311157947 : p_ratio_pred 0.01441784548422198 fp_ratio_pred 0.14966522252855455\n",
            "mse 29582.913670195714 / mse base 1105614.3590499812 : ratio 0.02675699119502695 mean ratio 0.01794674496106752 : p_ratio_pred 0.015206337944897718 fp_ratio_pred 0.15380070894052777\n",
            "mse 145932.4108403146 / mse base 1365189.0073213824 : ratio 0.1068953896183551 mean ratio 0.04736181639804138 : p_ratio_pred 0.015268881275137793 fp_ratio_pred 0.14946829460417488\n",
            "mse 94459.19928303696 / mse base 915765.1153817634 : ratio 0.10314784620689431 mean ratio 0.057490109577607876 : p_ratio_pred 0.0146148393194707 fp_ratio_pred 0.15005907837731391\n",
            "mse 46205.64518087114 / mse base 1293528.7919238745 : ratio 0.03572061593785567 mean ratio 0.05304680680143563 : p_ratio_pred 0.014808564755371314 fp_ratio_pred 0.15124064592359196\n",
            "VALIDATION: mse 32855.686333803664 / mse base 1612787.2127774516 : ratio 0.020371990845104385\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.015044749718812186 : fp 0.07529168029658707 fp_pred 0.07174790099225821\n",
            "MSE: 0.056918101653858 (0.04001331483619023) - 0.05304680680143563 + 0.020371990845104385\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.2, 'eta': 0.225, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.30000000000000004, 'learning_rate': 0.28, 'max_depth': 8, 'min_child_weight': 5.0, 'n_estimators': 120, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.54, 'tree_method': 'gpu_hist'}, 'threshold': 0.012}\n",
            "mse 39495.39763039663 / mse base 1657410.707915358 : ratio 0.023829577932480455 mean ratio 0.023829577932480455 : p_ratio_pred 0.01621564081941619 fp_ratio_pred 0.15852697912564\n",
            "mse 26210.953745619736 / mse base 1105614.3590499812 : ratio 0.02370713941174024 mean ratio 0.023780584606922284 : p_ratio_pred 0.01734657680028379 fp_ratio_pred 0.16167782591571483\n",
            "mse 145347.45452372852 / mse base 1365189.0073213824 : ratio 0.10646690952259619 mean ratio 0.05112472417899284 : p_ratio_pred 0.016522667461145044 fp_ratio_pred 0.15813312327688067\n",
            "mse 95298.75082835174 / mse base 915765.1153817634 : ratio 0.10406462227885113 mean ratio 0.06073628482758106 : p_ratio_pred 0.015926275992438562 fp_ratio_pred 0.1577392674281213\n",
            "mse 18663.64061478237 / mse base 1293528.7919238745 : ratio 0.014428469417386377 mean ratio 0.0512845424868744 : p_ratio_pred 0.016924074006138646 fp_ratio_pred 0.1636471051595116\n",
            "VALIDATION: mse 7321.41142853983 / mse base 1612787.2127774516 : ratio 0.004539601610513333\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.019197677436720725 : fp 0.07529168029658707 fp_pred 0.08325155381092575\n",
            "MSE: 0.05449934371261089 (0.041597629935039446) - 0.0512845424868744 + 0.004539601610513333\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.15000000000000002, 'eta': 0.35000000000000003, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.0, 'learning_rate': 0.04, 'max_depth': 12, 'min_child_weight': 50.0, 'n_estimators': 130, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.45, 'tree_method': 'gpu_hist'}, 'threshold': 0.019}\n",
            "mse 21821.894640955412 / mse base 1657410.707915358 : ratio 0.013166256581268467 mean ratio 0.013166256581268467 : p_ratio_pred 0.008161044613710556 fp_ratio_pred 0.10909807010634108\n",
            "mse 32663.244646961106 / mse base 1105614.3590499812 : ratio 0.029543072030131356 mean ratio 0.0197193792916827 : p_ratio_pred 0.008478183753103937 fp_ratio_pred 0.11343048444269398\n",
            "mse 144192.49835674663 / mse base 1365189.0073213824 : ratio 0.10562090493217832 mean ratio 0.04812677687481383 : p_ratio_pred 0.00875167585282288 fp_ratio_pred 0.10949192595510043\n",
            "mse 98728.89365353089 / mse base 915765.1153817634 : ratio 0.10781028016378727 mean ratio 0.05896268008150547 : p_ratio_pred 0.008128544423440454 fp_ratio_pred 0.10831035840882237\n",
            "mse 47449.866140640006 / mse base 1293528.7919238745 : ratio 0.036682497086181966 mean ratio 0.05441514210956238 : p_ratio_pred 0.008816659941059223 fp_ratio_pred 0.11244584482079559\n",
            "VALIDATION: mse 34867.903614130155 / mse base 1612787.2127774516 : ratio 0.021619655301013087\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.008055910712054064 : fp 0.07529168029658707 fp_pred 0.04274343037836659\n",
            "MSE: 0.05856460215870949 (0.04005375874363362) - 0.05441514210956238 + 0.021619655301013087\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.35000000000000003, 'eta': 0.225, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.9, 'learning_rate': 0.06, 'max_depth': 5, 'min_child_weight': 55.0, 'n_estimators': 160, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.56, 'tree_method': 'gpu_hist'}, 'threshold': 0.016}\n",
            "mse 22745.9750488966 / mse base 1657410.707915358 : ratio 0.01372380119198446 mean ratio 0.01372380119198446 : p_ratio_pred 0.012691015754364385 fp_ratio_pred 0.14139424970460812\n",
            "mse 32609.129871925838 / mse base 1105614.3590499812 : ratio 0.029494126595774148 mean ratio 0.020034239132553203 : p_ratio_pred 0.012805959560127705 fp_ratio_pred 0.14198503347774716\n",
            "mse 143872.65046033112 / mse base 1365189.0073213824 : ratio 0.10538661657012721 mean ratio 0.048260034919719225 : p_ratio_pred 0.013121306916927354 fp_ratio_pred 0.1380464749901536\n",
            "mse 95995.77816999328 / mse base 915765.1153817634 : ratio 0.10482576433365737 mean ratio 0.058529887307197714 : p_ratio_pred 0.012594517958412097 fp_ratio_pred 0.14080346593146909\n",
            "mse 47123.78309206434 / mse base 1293528.7919238745 : ratio 0.036430409115190084 mean ratio 0.054019232423466415 : p_ratio_pred 0.013255560854518997 fp_ratio_pred 0.14257581725088617\n",
            "VALIDATION: mse 33359.29555092632 / mse base 1612787.2127774516 : ratio 0.020684251019994642\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.012478009670938157 : fp 0.07529168029658707 fp_pred 0.06253407480100316\n",
            "MSE: 0.057972143561346653 (0.039182530816302165) - 0.054019232423466415 + 0.020684251019994642\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.55, 'eta': 0.07500000000000001, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.30000000000000004, 'learning_rate': 0.04, 'max_depth': 8, 'min_child_weight': 65.0, 'n_estimators': 150, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.87, 'tree_method': 'gpu_hist'}, 'threshold': 0.023}\n",
            "mse 21606.09259985704 / mse base 1657410.707915358 : ratio 0.01303605225709718 mean ratio 0.01303605225709718 : p_ratio_pred 0.012146946113450349 fp_ratio_pred 0.13509255612445845\n",
            "mse 32557.04887085424 / mse base 1105614.3590499812 : ratio 0.029447020658115785 mean ratio 0.019602841146207643 : p_ratio_pred 0.01248669741042923 fp_ratio_pred 0.13706183536825522\n",
            "mse 143942.5850094507 / mse base 1365189.0073213824 : ratio 0.10543784357880112 mean ratio 0.04798823968797959 : p_ratio_pred 0.012550275584686429 fp_ratio_pred 0.1321386372587633\n",
            "mse 95981.42074684305 / mse base 915765.1153817634 : ratio 0.10481008627068132 mean ratio 0.05830459170596497 : p_ratio_pred 0.012121928166351607 fp_ratio_pred 0.1346987002756991\n",
            "mse 47401.016012481276 / mse base 1293528.7919238745 : ratio 0.036644732075875486 mean ratio 0.053883665982174304 : p_ratio_pred 0.012778654144808442 fp_ratio_pred 0.13627412367073652\n",
            "VALIDATION: mse 34250.90969368947 / mse base 1612787.2127774516 : ratio 0.021237091553264784\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.01197812022341213 : fp 0.07529168029658707 fp_pred 0.0595354923127249\n",
            "MSE: 0.057875146968114174 (0.039330730816279726) - 0.053883665982174304 + 0.021237091553264784\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.8, 'eta': 0.375, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.5, 'learning_rate': 0.18, 'max_depth': 4, 'min_child_weight': 40.0, 'n_estimators': 80, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.8300000000000001, 'tree_method': 'gpu_hist'}, 'threshold': 0.029}\n",
            "mse 23625.5048361257 / mse base 1657410.707915358 : ratio 0.014254466152110939 mean ratio 0.014254466152110939 : p_ratio_pred 0.01166201447698349 fp_ratio_pred 0.12839700669554943\n",
            "mse 13006.59592508637 / mse base 1105614.3590499812 : ratio 0.011764134409634946 mean ratio 0.013257969027926884 : p_ratio_pred 0.011836348586969374 fp_ratio_pred 0.12879086254430877\n",
            "mse 21304.848620668763 / mse base 1365189.0073213824 : ratio 0.015605786822493318 mean ratio 0.014034385896494785 : p_ratio_pred 0.012140622672426635 fp_ratio_pred 0.12623079952737298\n",
            "mse 92172.88578629363 / mse base 915765.1153817634 : ratio 0.10065123058096472 mean ratio 0.02976020112764193 : p_ratio_pred 0.01167296786389414 fp_ratio_pred 0.12662465537613232\n",
            "mse 16544.668299869787 / mse base 1293528.7919238745 : ratio 0.012790336328936896 mean ratio 0.026296535476105345 : p_ratio_pred 0.012008266382968317 fp_ratio_pred 0.1278062229224104\n",
            "VALIDATION: mse 26967.875086767122 / mse base 1612787.2127774516 : ratio 0.016721285283707428\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.011651269430798958 : fp 0.07529168029658707 fp_pred 0.05735470504852252\n",
            "MSE: 0.03101319085882816 (0.03484335842216727) - 0.026296535476105345 + 0.016721285283707428\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.7000000000000001, 'eta': 0.45, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.7000000000000001, 'learning_rate': 0.14, 'max_depth': 10, 'min_child_weight': 30.0, 'n_estimators': 100, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.44, 'tree_method': 'gpu_hist'}, 'threshold': 0.017}\n",
            "mse 22629.897204397184 / mse base 1657410.707915358 : ratio 0.013653765537004644 mean ratio 0.013653765537004644 : p_ratio_pred 0.014216776269101575 fp_ratio_pred 0.1490744387554155\n",
            "mse 29314.351909717374 / mse base 1105614.3590499812 : ratio 0.026514083929686162 mean ratio 0.018799774831997993 : p_ratio_pred 0.014721532458318552 fp_ratio_pred 0.14572666404096102\n",
            "mse 149897.89142969722 / mse base 1365189.0073213824 : ratio 0.1098001013968093 mean ratio 0.048893331816540146 : p_ratio_pred 0.015033020507473063 fp_ratio_pred 0.14474202441906261\n",
            "mse 94788.16246829441 / mse base 915765.1153817634 : ratio 0.1035070684350967 mean ratio 0.05880878803379881 : p_ratio_pred 0.014331285444234405 fp_ratio_pred 0.14789287120913747\n",
            "mse 46905.22848350568 / mse base 1293528.7919238745 : ratio 0.03626144912765583 mean ratio 0.05420672171039938 : p_ratio_pred 0.014527312080413808 fp_ratio_pred 0.14808979913351714\n",
            "VALIDATION: mse 33196.54979187256 / mse base 1612787.2127774516 : ratio 0.02058334139114566\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.014669832633167665 : fp 0.07529168029658707 fp_pred 0.06934903500163558\n",
            "MSE: 0.057947293685250534 (0.040458981471019576) - 0.05420672171039938 + 0.02058334139114566\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.8, 'eta': 0.35000000000000003, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.30000000000000004, 'learning_rate': 0.18, 'max_depth': 1, 'min_child_weight': 45.0, 'n_estimators': 60, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.92, 'tree_method': 'gpu_hist'}, 'threshold': 0.023}\n",
            "mse 38297.629213662796 / mse base 1657410.707915358 : ratio 0.02310690345534959 mean ratio 0.02310690345534959 : p_ratio_pred 0.0060320764536121495 fp_ratio_pred 0.07778653012997243\n",
            "mse 52689.73785301748 / mse base 1105614.3590499812 : ratio 0.04765652455734391 mean ratio 0.032930344409293655 : p_ratio_pred 0.00595956012770486 fp_ratio_pred 0.07837731390311146\n",
            "mse 50468.81253651229 / mse base 1365189.0073213824 : ratio 0.036968370142048256 mean ratio 0.03426570838084107 : p_ratio_pred 0.006492377973087045 fp_ratio_pred 0.08054352107128791\n",
            "mse 79097.61696946669 / mse base 915765.1153817634 : ratio 0.08637325842718145 mean ratio 0.043726151175329325 : p_ratio_pred 0.005966446124763705 fp_ratio_pred 0.07818038597873178\n",
            "mse 359592.27298287075 / mse base 1293528.7919238745 : ratio 0.2779932501139357 mean ratio 0.09154167083348791 : p_ratio_pred 0.006529953409882975 fp_ratio_pred 0.08428515163450177\n",
            "VALIDATION: mse 62371.30009795457 / mse base 1612787.2127774516 : ratio 0.03867298773440931\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.006142872249406382 : fp 0.07529168029658707 fp_pred 0.03227565151019518\n",
            "MSE: 0.09441966133917179 (0.09416682893074131) - 0.09154167083348791 + 0.03867298773440931\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.8500000000000001, 'eta': 0.275, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.4, 'learning_rate': 0.22, 'max_depth': 1, 'min_child_weight': 65.0, 'n_estimators': 110, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.99, 'tree_method': 'gpu_hist'}, 'threshold': 0.015}\n",
            "mse 24161.910786035492 / mse base 1657410.707915358 : ratio 0.014578107086339286 mean ratio 0.014578107086339286 : p_ratio_pred 0.011117944836069451 fp_ratio_pred 0.1270185112248917\n",
            "mse 17580.848312323036 / mse base 1105614.3590499812 : ratio 0.015901429072818565 mean ratio 0.015107629531644119 : p_ratio_pred 0.01131606952820149 fp_ratio_pred 0.12760929499803073\n",
            "mse 22767.25828467567 / mse base 1365189.0073213824 : ratio 0.016677000886014294 mean ratio 0.015626616309664203 : p_ratio_pred 0.01156959134018571 fp_ratio_pred 0.12682158330051202\n",
            "mse 101248.19104319936 / mse base 915765.1153817634 : ratio 0.1105613102558412 mean ratio 0.03286258768984493 : p_ratio_pred 0.011235822306238185 fp_ratio_pred 0.1278062229224104\n",
            "mse 314688.2738760211 / mse base 1293528.7919238745 : ratio 0.24327890947675235 mean ratio 0.07581000034993848 : p_ratio_pred 0.011470217787397435 fp_ratio_pred 0.1295785742418275\n",
            "VALIDATION: mse 62238.982851253495 / mse base 1612787.2127774516 : ratio 0.03859094514028854\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.010968728069753804 : fp 0.07529168029658707 fp_pred 0.05511939810271508\n",
            "MSE: 0.08019935135555314 (0.0894340543012109) - 0.07581000034993848 + 0.03859094514028854\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.9500000000000001, 'eta': 0.375, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.8, 'learning_rate': 0.18, 'max_depth': 2, 'min_child_weight': 50.0, 'n_estimators': 60, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.46, 'tree_method': 'gpu_hist'}, 'threshold': 0.018000000000000002}\n",
            "mse 17245.378943810036 / mse base 1657410.707915358 : ratio 0.01040501238555455 mean ratio 0.01040501238555455 : p_ratio_pred 0.01007711595779912 fp_ratio_pred 0.114021268215833\n",
            "mse 17565.509107520225 / mse base 1105614.3590499812 : ratio 0.01588755515314915 mean ratio 0.012598831790391044 : p_ratio_pred 0.010429230223483505 fp_ratio_pred 0.1165813312327688\n",
            "mse 22702.675385670453 / mse base 1365189.0073213824 : ratio 0.016629693957333457 mean ratio 0.013931826790483964 : p_ratio_pred 0.010650975718754655 fp_ratio_pred 0.11520283576211107\n",
            "mse 101637.51922292751 / mse base 915765.1153817634 : ratio 0.11098645003588824 mean ratio 0.03155268423508076 : p_ratio_pred 0.010420604914933837 fp_ratio_pred 0.11677825915714848\n",
            "mse 314672.71195415966 / mse base 1293528.7919238745 : ratio 0.24326687888109913 mean ratio 0.07476500163634274 : p_ratio_pred 0.010345207087567409 fp_ratio_pred 0.11500590783773139\n",
            "VALIDATION: mse 62067.01366285172 / mse base 1612787.2127774516 : ratio 0.0384843165738916\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.00991126962306413 : fp 0.07529168029658707 fp_pred 0.049830988987024316\n",
            "MSE: 0.07943511808260491 (0.09009362013010203) - 0.07476500163634274 + 0.0384843165738916\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.9500000000000001, 'eta': 0.5, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.9, 'learning_rate': 0.04, 'max_depth': 13, 'min_child_weight': 70.0, 'n_estimators': 60, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.53, 'tree_method': 'gpu_hist'}, 'threshold': 0.02}\n",
            "mse 45205.55973464929 / mse base 1657410.707915358 : ratio 0.027274808542481 mean ratio 0.027274808542481 : p_ratio_pred 0.02055637034583905 fp_ratio_pred 0.22016541945647894\n",
            "mse 52333.43658746001 / mse base 1105614.3590499812 : ratio 0.04733425914658747 mean ratio 0.03530152422005981 : p_ratio_pred 0.020834811398841198 fp_ratio_pred 0.2221346987002757\n",
            "mse 156750.23089950142 / mse base 1365189.0073213824 : ratio 0.11481943530080042 mean ratio 0.06159787807650144 : p_ratio_pred 0.021860569045136304 fp_ratio_pred 0.22016541945647894\n",
            "mse 108837.40607587714 / mse base 915765.1153817634 : ratio 0.11884860456876553 mean ratio 0.07199209585187728 : p_ratio_pred 0.020309546313799623 fp_ratio_pred 0.2170145726664041\n",
            "mse 117686.02249876516 / mse base 1293528.7919238745 : ratio 0.09098059759746817 mean ratio 0.07586777913223934 : p_ratio_pred 0.022133362681438545 fp_ratio_pred 0.23020874359984245\n",
            "VALIDATION: mse 122522.22681148528 / mse base 1612787.2127774516 : ratio 0.07596924494489535\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.02067811926208627 : fp 0.07529168029658707 fp_pred 0.09949841892923346\n",
            "MSE: 0.07985154103122052 (0.03657613132798969) - 0.07586777913223934 + 0.07596924494489535\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.55, 'eta': 0.25, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 1.0, 'learning_rate': 0.06, 'max_depth': 10, 'min_child_weight': 75.0, 'n_estimators': 60, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.64, 'tree_method': 'gpu_hist'}, 'threshold': 0.016}\n",
            "mse 14330.381581718502 / mse base 1657410.707915358 : ratio 0.008646246529771025 mean ratio 0.008646246529771025 : p_ratio_pred 0.014476983488669158 fp_ratio_pred 0.1699487987396613\n",
            "mse 34265.7938490542 / mse base 1105614.3590499812 : ratio 0.03099253692625491 mean ratio 0.01758803277313239 : p_ratio_pred 0.015005321035828308 fp_ratio_pred 0.17487199684915322\n",
            "mse 149289.87396873714 / mse base 1365189.0073213824 : ratio 0.109354729028808 mean ratio 0.04793502610053013 : p_ratio_pred 0.015281294999751725 fp_ratio_pred 0.17053958251280033\n",
            "mse 100310.33284002548 / mse base 915765.1153817634 : ratio 0.1095371849780587 mean ratio 0.059119272904679505 : p_ratio_pred 0.014390359168241966 fp_ratio_pred 0.16876723119338322\n",
            "mse 48053.46027472626 / mse base 1293528.7919238745 : ratio 0.03714912306146353 mean ratio 0.05463501482285519 : p_ratio_pred 0.015395526859630458 fp_ratio_pred 0.17487199684915322\n",
            "VALIDATION: mse 36172.59479169033 / mse base 1612787.2127774516 : ratio 0.022428622018521537\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.014804418253655442 : fp 0.07529168029658707 fp_pred 0.07523716061498201\n",
            "MSE: 0.05913596410487123 (0.04215896741912209) - 0.05463501482285519 + 0.022428622018521537\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.9, 'eta': 0.42500000000000004, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.8, 'learning_rate': 0.18, 'max_depth': 15, 'min_child_weight': 45.0, 'n_estimators': 50, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.6, 'tree_method': 'gpu_hist'}, 'threshold': 0.005}\n",
            "mse 14571.11590466982 / mse base 1657410.707915358 : ratio 0.008791493764992588 mean ratio 0.008791493764992588 : p_ratio_pred 0.015896295595401427 fp_ratio_pred 0.16187475384009453\n",
            "mse 40814.97067095968 / mse base 1105614.3590499812 : ratio 0.03691610038967897 mean ratio 0.020045452079977197 : p_ratio_pred 0.017535769185290293 fp_ratio_pred 0.17014572666404096\n",
            "mse 146129.67959273013 / mse base 1365189.0073213824 : ratio 0.10703988884253401 mean ratio 0.04881427235654628 : p_ratio_pred 0.016609563533442576 fp_ratio_pred 0.16187475384009453\n",
            "mse 96696.28296980295 / mse base 915765.1153817634 : ratio 0.10559070371390188 mean ratio 0.059122378964010465 : p_ratio_pred 0.016150756143667296 fp_ratio_pred 0.16463174478141002\n",
            "mse 47505.270100277165 / mse base 1293528.7919238745 : ratio 0.03672532872625297 mean ratio 0.054550987587328445 : p_ratio_pred 0.016765105102901794 fp_ratio_pred 0.16876723119338322\n",
            "VALIDATION: mse 34459.51467373792 / mse base 1612787.2127774516 : ratio 0.021366435944388272\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.01688088211260971 : fp 0.07529168029658707 fp_pred 0.07921709737215135\n",
            "MSE: 0.059012703087472085 (0.03995817184612045) - 0.054550987587328445 + 0.021366435944388272\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.8, 'eta': 0.30000000000000004, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.4, 'learning_rate': 0.28, 'max_depth': 6, 'min_child_weight': 25.0, 'n_estimators': 50, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.41000000000000003, 'tree_method': 'gpu_hist'}, 'threshold': 0.009000000000000001}\n",
            "mse 22085.17363427877 / mse base 1657410.707915358 : ratio 0.013325106160353487 mean ratio 0.013325106160353487 : p_ratio_pred 0.014973742726025453 fp_ratio_pred 0.15419456478928711\n",
            "mse 25609.539981526075 / mse base 1105614.3590499812 : ratio 0.023163175995228144 mean ratio 0.017261773766022497 : p_ratio_pred 0.016022230105238264 fp_ratio_pred 0.15655769988184323\n",
            "mse 145919.1786528933 / mse base 1365189.0073213824 : ratio 0.1068856970502562 mean ratio 0.04690015798227494 : p_ratio_pred 0.015839912607378718 fp_ratio_pred 0.15320992516738874\n",
            "mse 96234.30955919324 / mse base 915765.1153817634 : ratio 0.10508623657178201 mean ratio 0.057464194622686704 : p_ratio_pred 0.01550094517958412 fp_ratio_pred 0.1561638440330839\n",
            "mse 46827.67567619995 / mse base 1293528.7919238745 : ratio 0.036201494677635136 mean ratio 0.05312433191121573 : p_ratio_pred 0.015358841728114261 fp_ratio_pred 0.15675462780622293\n",
            "VALIDATION: mse 27299.94321982105 / mse base 1612787.2127774516 : ratio 0.016927182335980093\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.01608298164828932 : fp 0.07529168029658707 fp_pred 0.07545523934140225\n",
            "MSE: 0.05693234209105099 (0.040708355073971844) - 0.05312433191121573 + 0.016927182335980093\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.1, 'eta': 0.025, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.4, 'learning_rate': 0.28, 'max_depth': 10, 'min_child_weight': 25.0, 'n_estimators': 100, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.44, 'tree_method': 'gpu_hist'}, 'threshold': 0.01}\n",
            "mse 14243.867623977372 / mse base 1657410.707915358 : ratio 0.008594048268152488 mean ratio 0.008594048268152488 : p_ratio_pred 0.014701707905568434 fp_ratio_pred 0.1526191413942497\n",
            "mse 32542.272940679697 / mse base 1105614.3590499812 : ratio 0.02943365620598689 mean ratio 0.01693294104495505 : p_ratio_pred 0.015324583185526782 fp_ratio_pred 0.15754233950374164\n",
            "mse 142618.03165441556 / mse base 1365189.0073213824 : ratio 0.1044676091658871 mean ratio 0.0458804143415935 : p_ratio_pred 0.015380604796663191 fp_ratio_pred 0.15360378101614808\n",
            "mse 98962.65509063994 / mse base 915765.1153817634 : ratio 0.10806554369499483 mean ratio 0.057170502983115094 : p_ratio_pred 0.01498109640831758 fp_ratio_pred 0.15596691610870422\n",
            "mse 46749.61019384049 / mse base 1293528.7919238745 : ratio 0.03614114388927475 mean ratio 0.05287826673779619 : p_ratio_pred 0.015224329579221542 fp_ratio_pred 0.1577392674281213\n",
            "VALIDATION: mse 27353.024544459084 / mse base 1612787.2127774516 : ratio 0.016960095124609303\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.015535025907731944 : fp 0.07529168029658707 fp_pred 0.07414676698288082\n",
            "MSE: 0.057340400244859216 (0.04098393749419631) - 0.05287826673779619 + 0.016960095124609303\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.75, 'eta': 0.125, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 1.0, 'learning_rate': 0.08, 'max_depth': 12, 'min_child_weight': 60.0, 'n_estimators': 60, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.73, 'tree_method': 'gpu_hist'}, 'threshold': 0.015}\n",
            "mse 14489.14525029724 / mse base 1657410.707915358 : ratio 0.00874203670888627 mean ratio 0.00874203670888627 : p_ratio_pred 0.013554430619293182 fp_ratio_pred 0.15025600630169358\n",
            "mse 32572.160584253288 / mse base 1105614.3590499812 : ratio 0.029460688817610416 mean ratio 0.017032529453755003 : p_ratio_pred 0.014094832682984509 fp_ratio_pred 0.15419456478928711\n",
            "mse 145860.68627724075 / mse base 1365189.0073213824 : ratio 0.1068428514257025 mean ratio 0.04673255520188221 : p_ratio_pred 0.014511644073687869 fp_ratio_pred 0.1510437179992123\n",
            "mse 98676.60272026711 / mse base 915765.1153817634 : ratio 0.10775317935006826 mean ratio 0.05781122083717869 : p_ratio_pred 0.013657844990548205 fp_ratio_pred 0.14986215045293422\n",
            "mse 46798.41644467412 / mse base 1293528.7919238745 : ratio 0.03617887497894075 mean ratio 0.0533959108626964 : p_ratio_pred 0.014466170194553481 fp_ratio_pred 0.15458842063804648\n",
            "VALIDATION: mse 35305.15634847713 / mse base 1612787.2127774516 : ratio 0.021890771497175113\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.013689280255328149 : fp 0.07529168029658707 fp_pred 0.06831316105113946\n",
            "MSE: 0.05779552625624164 (0.04141930629745638) - 0.0533959108626964 + 0.021890771497175113\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.75, 'eta': 0.275, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.1, 'learning_rate': 0.28, 'max_depth': 2, 'min_child_weight': 15.0, 'n_estimators': 100, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.64, 'tree_method': 'gpu_hist'}, 'threshold': 0.021}\n",
            "mse 23416.596741395562 / mse base 1657410.707915358 : ratio 0.014128421295677679 mean ratio 0.014128421295677679 : p_ratio_pred 0.011425462459194777 fp_ratio_pred 0.12544308782985428\n",
            "mse 12796.296690999958 / mse base 1105614.3590499812 : ratio 0.011573924114006083 mean ratio 0.01310624860604994 : p_ratio_pred 0.011398841196641835 fp_ratio_pred 0.12268609688853879\n",
            "mse 20306.957780848883 / mse base 1365189.0073213824 : ratio 0.014874832475169773 mean ratio 0.013691114413200573 : p_ratio_pred 0.011904761904761904 fp_ratio_pred 0.12445844820795589\n",
            "mse 101185.54149641322 / mse base 915765.1153817634 : ratio 0.11049289801155078 mean ratio 0.03126606728130113 : p_ratio_pred 0.011224007561436673 fp_ratio_pred 0.12111067349350138\n",
            "mse 16744.990830701372 / mse base 1293528.7919238745 : ratio 0.012945201479277805 mean ratio 0.027526653070427638 : p_ratio_pred 0.011580273181946025 fp_ratio_pred 0.12248916896415912\n",
            "VALIDATION: mse 27711.587796012933 / mse base 1612787.2127774516 : ratio 0.017182420331997544\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.011324418638185786 : fp 0.07529168029658707 fp_pred 0.056264311416421325\n",
            "MSE: 0.03280305547513642 (0.03886099627820925) - 0.027526653070427638 + 0.017182420331997544\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.8500000000000001, 'eta': 0.15000000000000002, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.0, 'learning_rate': 0.2, 'max_depth': 15, 'min_child_weight': 40.0, 'n_estimators': 50, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.54, 'tree_method': 'gpu_hist'}, 'threshold': 0.021}\n",
            "mse 21736.687313339193 / mse base 1657410.707915358 : ratio 0.013114846675920751 mean ratio 0.013114846675920751 : p_ratio_pred 0.013140464588162938 fp_ratio_pred 0.14040961008270972\n",
            "mse 25340.801551926565 / mse base 1105614.3590499812 : ratio 0.022920108937171457 mean ratio 0.017038386451184634 : p_ratio_pred 0.013479957431713374 fp_ratio_pred 0.139621898385191\n",
            "mse 149925.42184987653 / mse base 1365189.0073213824 : ratio 0.10982026741047603 mean ratio 0.04772109855983685 : p_ratio_pred 0.013828889219921545 fp_ratio_pred 0.13607719574635682\n",
            "mse 94061.38137422077 / mse base 915765.1153817634 : ratio 0.10271343578643366 mean ratio 0.05770529202133628 : p_ratio_pred 0.013362476370510397 fp_ratio_pred 0.14040961008270972\n",
            "mse 47232.4167830014 / mse base 1293528.7919238745 : ratio 0.036514391544970784 mean ratio 0.053380084073261266 : p_ratio_pred 0.013879208090294337 fp_ratio_pred 0.1439543127215439\n",
            "VALIDATION: mse 34278.77365122609 / mse base 1612787.2127774516 : ratio 0.021254368449631435\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.0136412139622968 : fp 0.07529168029658707 fp_pred 0.06602333442372696\n",
            "MSE: 0.05701661007099453 (0.040955349570348604) - 0.053380084073261266 + 0.021254368449631435\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.30000000000000004, 'eta': 0.17500000000000002, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.6000000000000001, 'learning_rate': 0.1, 'max_depth': 7, 'min_child_weight': 0.0, 'n_estimators': 140, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.29, 'tree_method': 'gpu_hist'}, 'threshold': 0.002}\n",
            "mse 19813.58965321806 / mse base 1657410.707915358 : ratio 0.011954544253028873 mean ratio 0.011954544253028873 : p_ratio_pred 0.01926716184889057 fp_ratio_pred 0.1845214651437574\n",
            "mse 53248.56590712289 / mse base 1105614.3590499812 : ratio 0.04816197028489903 mean ratio 0.026442813144864415 : p_ratio_pred 0.022383824051081944 fp_ratio_pred 0.19318629381646318\n",
            "mse 145506.0248776676 / mse base 1365189.0073213824 : ratio 0.10658306219675975 mean ratio 0.05294497245174309 : p_ratio_pred 0.01997368290381846 fp_ratio_pred 0.1886569515557306\n",
            "mse 102833.886955358 / mse base 915765.1153817634 : ratio 0.11229286334246166 mean ratio 0.0637199431852713 : p_ratio_pred 0.019246219281663517 fp_ratio_pred 0.19062623079952737\n",
            "mse 49539.24927894879 / mse base 1293528.7919238745 : ratio 0.03829775540231208 mean ratio 0.05853110051296737 : p_ratio_pred 0.0198466561502623 fp_ratio_pred 0.19279243796770382\n",
            "VALIDATION: mse 100652.08785704951 / mse base 1612787.2127774516 : ratio 0.062408783415210826\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.022860328965709508 : fp 0.07529168029658707 fp_pred 0.09671791516737542\n",
            "MSE: 0.06345803909589227 (0.039406160062316675) - 0.05853110051296737 + 0.062408783415210826\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.4, 'eta': 0.2, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.2, 'learning_rate': 0.24, 'max_depth': 11, 'min_child_weight': 5.0, 'n_estimators': 190, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.16, 'tree_method': 'gpu_hist'}, 'threshold': 0.007}\n",
            "mse 39716.303579075735 / mse base 1657410.707915358 : ratio 0.023962861703137977 mean ratio 0.023962861703137977 : p_ratio_pred 0.017575814921701283 fp_ratio_pred 0.16522252855454903\n",
            "mse 36304.155316395925 / mse base 1105614.3590499812 : ratio 0.03283618290521382 mean ratio 0.027513488677453717 : p_ratio_pred 0.0195577628000473 fp_ratio_pred 0.1723119338322174\n",
            "mse 141562.99092028657 / mse base 1365189.0073213824 : ratio 0.10369479256066182 mean ratio 0.05270643573719044 : p_ratio_pred 0.01765231640101296 fp_ratio_pred 0.16581331232768806\n",
            "mse 99814.04768138107 / mse base 915765.1153817634 : ratio 0.10899524998806126 mean ratio 0.06292601249173674 : p_ratio_pred 0.01704867674858223 fp_ratio_pred 0.16699487987396613\n",
            "mse 24605.56516537144 / mse base 1293528.7919238745 : ratio 0.019022046759991643 mean ratio 0.05396491233713274 : p_ratio_pred 0.017657776636462574 fp_ratio_pred 0.17132729421031903\n",
            "VALIDATION: mse 14878.554935057262 / mse base 1612787.2127774516 : ratio 0.009225367622697262\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.02072618555511762 : fp 0.07529168029658707 fp_pred 0.08843092356340639\n",
            "MSE: 0.0577022267834133 (0.03999777883099019) - 0.05396491233713274 + 0.009225367622697262\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.30000000000000004, 'eta': 0.2, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.2, 'learning_rate': 0.24, 'max_depth': 11, 'min_child_weight': 0.0, 'n_estimators': 190, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.17, 'tree_method': 'gpu_hist'}, 'threshold': 0.006}\n",
            "mse 26124.677921331364 / mse base 1657410.707915358 : ratio 0.015762344116981245 mean ratio 0.015762344116981245 : p_ratio_pred 0.016475848038983772 fp_ratio_pred 0.16167782591571483\n",
            "mse 27376.979978465737 / mse base 1105614.3590499812 : ratio 0.02476178041138132 mean ratio 0.01936343558350651 : p_ratio_pred 0.01874187063970675 fp_ratio_pred 0.1636471051595116\n",
            "mse 143765.00500492746 / mse base 1365189.0073213824 : ratio 0.10530776634878324 mean ratio 0.04778498870333137 : p_ratio_pred 0.016857838025721238 fp_ratio_pred 0.16167782591571483\n",
            "mse 98388.55999612587 / mse base 915765.1153817634 : ratio 0.10743864157252783 mean ratio 0.058615472384667466 : p_ratio_pred 0.016221644612476372 fp_ratio_pred 0.16305632138637258\n",
            "mse 25600.11436808668 / mse base 1293528.7919238745 : ratio 0.01979091190541762 mean ratio 0.05069111363678609 : p_ratio_pred 0.016985215891998973 fp_ratio_pred 0.16699487987396613\n",
            "VALIDATION: mse 13767.375440296986 / mse base 1612787.2127774516 : ratio 0.00853638677887803\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.021658671639925787 : fp 0.07529168029658707 fp_pred 0.09050267146439865\n",
            "MSE: 0.054612288871018246 (0.042364027978731934) - 0.05069111363678609 + 0.00853638677887803\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.2, 'eta': 0.2, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.2, 'learning_rate': 0.24, 'max_depth': 8, 'min_child_weight': 5.0, 'n_estimators': 120, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.11, 'tree_method': 'gpu_hist'}, 'threshold': 0.002}\n",
            "mse 27751.412152556946 / mse base 1657410.707915358 : ratio 0.016743835441646114 mean ratio 0.016743835441646114 : p_ratio_pred 0.019361782656006056 fp_ratio_pred 0.18294604174871998\n",
            "mse 52832.806805021726 / mse base 1105614.3590499812 : ratio 0.047785926776872954 mean ratio 0.029165214576241688 : p_ratio_pred 0.02179259784793662 fp_ratio_pred 0.189641591177629\n",
            "mse 148130.45818549735 / mse base 1365189.0073213824 : ratio 0.10850545777257757 mean ratio 0.055402814153380275 : p_ratio_pred 0.019799890759223397 fp_ratio_pred 0.18314296967309965\n",
            "mse 101704.83650359321 / mse base 915765.1153817634 : ratio 0.11105995936653973 mean ratio 0.06550770755031327 : p_ratio_pred 0.019647920604914933 fp_ratio_pred 0.18550610476565577\n",
            "mse 49075.68543303581 / mse base 1293528.7919238745 : ratio 0.037939383908142624 mean ratio 0.05988082384779155 : p_ratio_pred 0.020225735842596328 fp_ratio_pred 0.19141394249704607\n",
            "VALIDATION: mse 21710.131196466828 / mse base 1612787.2127774516 : ratio 0.013461249583619193\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.022504638397277524 : fp 0.07529168029658707 fp_pred 0.09791734816268673\n",
            "MSE: 0.0644069126531558 (0.038392042477390774) - 0.05988082384779155 + 0.013461249583619193\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.25, 'eta': 0.025, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.2, 'learning_rate': 0.26, 'max_depth': 14, 'min_child_weight': 10.0, 'n_estimators': 170, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.27, 'tree_method': 'gpu_hist'}, 'threshold': 0.005}\n",
            "mse 40636.14440665761 / mse base 1657410.707915358 : ratio 0.024517848359848323 mean ratio 0.024517848359848323 : p_ratio_pred 0.017776884136821686 fp_ratio_pred 0.1679795194958645\n",
            "mse 40306.27345264688 / mse base 1105614.3590499812 : ratio 0.036455996725007045 mean ratio 0.029294854696415924 : p_ratio_pred 0.01981790232943124 fp_ratio_pred 0.17053958251280033\n",
            "mse 146544.7941996928 / mse base 1365189.0073213824 : ratio 0.10734396000391641 mean ratio 0.055105478535122446 : p_ratio_pred 0.01819852028402602 fp_ratio_pred 0.16738873572272547\n",
            "mse 91830.68068135336 / mse base 915765.1153817634 : ratio 0.10027754840068467 mean ratio 0.06330674269917791 : p_ratio_pred 0.01755671077504726 fp_ratio_pred 0.16935801496652225\n",
            "mse 46321.31798130079 / mse base 1293528.7919238745 : ratio 0.035810040155663456 mean ratio 0.0576944773535072 : p_ratio_pred 0.018195825232033457 fp_ratio_pred 0.17250886175659708\n",
            "VALIDATION: mse 15447.657416827475 / mse base 1612787.2127774516 : ratio 0.00957823654257798\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.02112994241658095 : fp 0.07529168029658707 fp_pred 0.08946679751390252\n",
            "MSE: 0.060881078729023985 (0.035378827815196065) - 0.0576944773535072 + 0.00957823654257798\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.45, 'eta': 0.15000000000000002, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.1, 'learning_rate': 0.3, 'max_depth': 11, 'min_child_weight': 0.0, 'n_estimators': 190, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.35000000000000003, 'tree_method': 'gpu_hist'}, 'threshold': 0.013000000000000001}\n",
            "mse 26548.36034929738 / mse base 1657410.707915358 : ratio 0.016017973229272255 mean ratio 0.016017973229272255 : p_ratio_pred 0.015482329564271183 fp_ratio_pred 0.15143757384797163\n",
            "mse 38854.30756718732 / mse base 1105614.3590499812 : ratio 0.03514273059964017 mean ratio 0.023670674833333006 : p_ratio_pred 0.017145559891214378 fp_ratio_pred 0.15990547459629775\n",
            "mse 151168.44294879667 / mse base 1365189.0073213824 : ratio 0.11073077950239439 mean ratio 0.052461211305448306 : p_ratio_pred 0.015988877302745917 fp_ratio_pred 0.15360378101614808\n",
            "mse 94248.71548810936 / mse base 915765.1153817634 : ratio 0.1029180014668052 mean ratio 0.06162194859765456 : p_ratio_pred 0.014910207939508507 fp_ratio_pred 0.15045293422607325\n",
            "mse 25582.66456640607 / mse base 1293528.7919238745 : ratio 0.0197774218294413 mean ratio 0.05308119404297341 : p_ratio_pred 0.016190371375814715 fp_ratio_pred 0.15990547459629775\n",
            "VALIDATION: mse 11797.076639709163 / mse base 1612787.2127774516 : ratio 0.007314713649913493\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.020005191159647384 : fp 0.07529168029658707 fp_pred 0.08554138043833824\n",
            "MSE: 0.05691738132551066 (0.04132363116898969) - 0.05308119404297341 + 0.007314713649913493\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.45, 'eta': 0.15000000000000002, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.1, 'learning_rate': 0.26, 'max_depth': 8, 'min_child_weight': 15.0, 'n_estimators': 180, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.33, 'tree_method': 'gpu_hist'}, 'threshold': 0.011}\n",
            "mse 37726.02869511942 / mse base 1657410.707915358 : ratio 0.022762027851606016 mean ratio 0.022762027851606016 : p_ratio_pred 0.015955433599848606 fp_ratio_pred 0.15399763686490744\n",
            "mse 36068.94910636116 / mse base 1105614.3590499812 : ratio 0.03262344488484578 mean ratio 0.026708037753175512 : p_ratio_pred 0.017559418233416106 fp_ratio_pred 0.1569515557306026\n",
            "mse 143557.366291491 / mse base 1365189.0073213824 : ratio 0.10515567113535643 mean ratio 0.0526504537269003 : p_ratio_pred 0.016857838025721238 fp_ratio_pred 0.15714848365498227\n",
            "mse 92010.24023452663 / mse base 915765.1153817634 : ratio 0.10047362439239615 mean ratio 0.061333041373596756 : p_ratio_pred 0.01585538752362949 fp_ratio_pred 0.15833005120126034\n",
            "mse 25097.98308125853 / mse base 1293528.7919238745 : ratio 0.019402724730951 mean ratio 0.052774776517870416 : p_ratio_pred 0.016410482164911894 fp_ratio_pred 0.16010240252067742\n",
            "VALIDATION: mse 10611.802367675065 / mse base 1612787.2127774516 : ratio 0.006579790739659955\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.01858242888591946 : fp 0.07529168029658707 fp_pred 0.08167048304437902\n",
            "MSE: 0.05608349859903108 (0.0384310683952212) - 0.052774776517870416 + 0.006579790739659955\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.45, 'eta': 0.30000000000000004, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.30000000000000004, 'learning_rate': 0.3, 'max_depth': 8, 'min_child_weight': 15.0, 'n_estimators': 180, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.35000000000000003, 'tree_method': 'gpu_hist'}, 'threshold': 0.011}\n",
            "mse 26220.835432763408 / mse base 1657410.707915358 : ratio 0.01582036082398864 mean ratio 0.01582036082398864 : p_ratio_pred 0.01602639920518522 fp_ratio_pred 0.15636077195746356\n",
            "mse 30842.65607255899 / mse base 1105614.3590499812 : ratio 0.02789639608069227 mean ratio 0.02065254209510153 : p_ratio_pred 0.017370225848409603 fp_ratio_pred 0.15872390705001968\n",
            "mse 140940.7527014426 / mse base 1365189.0073213824 : ratio 0.10323900349738416 mean ratio 0.04796365707875177 : p_ratio_pred 0.01663439098267044 fp_ratio_pred 0.15596691610870422\n",
            "mse 91524.57130204352 / mse base 915765.1153817634 : ratio 0.0999432821416099 mean ratio 0.05740087431404287 : p_ratio_pred 0.01617438563327032 fp_ratio_pred 0.16089011421819613\n",
            "mse 46118.223635481634 / mse base 1293528.7919238745 : ratio 0.03565303217324577 mean ratio 0.05296199075712338 : p_ratio_pred 0.016520537559460483 fp_ratio_pred 0.16148089799133516\n",
            "VALIDATION: mse 14280.527152588504 / mse base 1612787.2127774516 : ratio 0.00885456372635506\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.01903425204041414 : fp 0.07529168029658707 fp_pred 0.08292443572129539\n",
            "MSE: 0.056510414943384144 (0.037361605792689434) - 0.05296199075712338 + 0.00885456372635506\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.1, 'eta': 0.1, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.5, 'learning_rate': 0.26, 'max_depth': 3, 'min_child_weight': 10.0, 'n_estimators': 180, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.74, 'tree_method': 'gpu_hist'}, 'threshold': 0.008}\n",
            "mse 15510.143893889433 / mse base 1657410.707915358 : ratio 0.009358057010140614 mean ratio 0.009358057010140614 : p_ratio_pred 0.01492643232246771 fp_ratio_pred 0.15478534856242615\n",
            "mse 36978.676307676134 / mse base 1105614.3590499812 : ratio 0.033446269944839284 mean ratio 0.01899686717616884 : p_ratio_pred 0.01614047534586733 fp_ratio_pred 0.15596691610870422\n",
            "mse 18738.23330484404 / mse base 1365189.0073213824 : ratio 0.013725742885675631 mean ratio 0.017253720912890475 : p_ratio_pred 0.01569094791201152 fp_ratio_pred 0.15498227648680582\n",
            "mse 95912.74931892991 / mse base 915765.1153817634 : ratio 0.10473509823416442 mean ratio 0.033136497305082016 : p_ratio_pred 0.015099243856332703 fp_ratio_pred 0.1543914927136668\n",
            "mse 25724.80027973943 / mse base 1293528.7919238745 : ratio 0.01988730397062036 mean ratio 0.030432246186555476 : p_ratio_pred 0.015566724140039375 fp_ratio_pred 0.1604962583694368\n",
            "VALIDATION: mse 18906.455254973625 / mse base 1612787.2127774516 : ratio 0.011722845459826029\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.015871489958951386 : fp 0.07529168029658707 fp_pred 0.07463744411732635\n",
            "MSE: 0.03623049440908806 (0.035203193769022985) - 0.030432246186555476 + 0.011722845459826029\n",
            "---------------- \n",
            "\n",
            "Training with params: \n",
            "{'model': {'colsample_bytree': 0.6000000000000001, 'eta': 0.07500000000000001, 'eval_metric': ('auc', 'error', 'logloss'), 'gamma': 0.0, 'learning_rate': 0.22, 'max_depth': 8, 'min_child_weight': 35.0, 'n_estimators': 90, 'objective': 'binary:logistic', 'seed': 0, 'subsample': 0.21, 'tree_method': 'gpu_hist'}, 'threshold': 0.013000000000000001}\n",
            "mse 22594.35721290393 / mse base 1657410.707915358 : ratio 0.013632322456346649 mean ratio 0.013632322456346649 : p_ratio_pred 0.013767327435303024 fp_ratio_pred 0.14474202441906261\n",
            "mse 33212.067654972954 / mse base 1105614.3590499812 : ratio 0.03003946844857461 mean ratio 0.02019758182258176 : p_ratio_pred 0.014236726971739387 fp_ratio_pred 0.14513588026782198\n",
            "mse 145859.6427422533 / mse base 1365189.0073213824 : ratio 0.10684208703704873 mean ratio 0.048850680701430026 : p_ratio_pred 0.014486816624460002 fp_ratio_pred 0.14198503347774716\n",
            "mse 95985.11678005011 / mse base 915765.1153817634 : ratio 0.10481412227636114 mean ratio 0.059011184066709715 : p_ratio_pred 0.014189508506616258 fp_ratio_pred 0.1482867270578968\n",
            "mse 25338.26326444272 / mse base 1293528.7919238745 : ratio 0.01958848030491609 mean ratio 0.0509647401774899 : p_ratio_pred 0.01433165804566076 fp_ratio_pred 0.14690823158723906\n",
            "VALIDATION: mse 33387.42674976208 / mse base 1612787.2127774516 : ratio 0.020701693617885358\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.014304528806129414 : fp 0.07529168029658707 fp_pred 0.06913095627521536\n",
            "MSE: 0.05498329610464945 (0.041850533997121936) - 0.0509647401774899 + 0.020701693617885358\n",
            "---------------- \n",
            "\n",
            "100%|██████████| 30/30 [08:23<00:00, 16.77s/it, best loss: 0.004539601610513333]\n",
            "---------------- \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model': {'colsample_bytree': 0.2,\n",
              "  'eta': 0.225,\n",
              "  'eval_metric': ('auc', 'error', 'logloss'),\n",
              "  'gamma': 0.30000000000000004,\n",
              "  'learning_rate': 0.28,\n",
              "  'max_depth': 8,\n",
              "  'min_child_weight': 5.0,\n",
              "  'n_estimators': 120,\n",
              "  'objective': 'binary:logistic',\n",
              "  'seed': 0,\n",
              "  'subsample': 0.54,\n",
              "  'tree_method': 'gpu_hist'},\n",
              " 'threshold': 0.012}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P23E0d08BPb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import json\n",
        "# with open('best.json', 'w') as f:\n",
        "#   f.write(json.dumps(best))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qlGw86u8rQk0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best = {'model': {'colsample_bytree': 0.2,\n",
        "  'eta': 0.225,\n",
        "  'eval_metric': ['auc', 'error', 'logloss'],\n",
        "  'gamma': 0.30000000000000004,\n",
        "  'learning_rate': 0.28,\n",
        "  'max_depth': 8,\n",
        "  'min_child_weight': 5.0,\n",
        "  'n_estimators': 120,\n",
        "  'objective': 'binary:logistic',\n",
        "  'seed': 0,\n",
        "  'subsample': 0.54,\n",
        "  'tree_method': 'gpu_hist'},\n",
        " 'threshold': 0.012}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSCDVS71A11Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B67NGhvA14t",
        "colab_type": "code",
        "outputId": "6d73050f-7d54-4535-c326-ffd2b4479327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "# model eli + best\n",
        "\n",
        "model = xgb.XGBClassifier(**best['model'])\n",
        "\n",
        "feats = feats_eli\n",
        "\n",
        "threshold = best['threshold']\n",
        "\n",
        "scenario={\n",
        "    'opt': '3', \n",
        "    'fun': np.mean\n",
        "}\n",
        "\n",
        "### run\n",
        "\n",
        "scores, ratio, scores_validation, submission = run_model(model, feats, train, data_to_predict=test, data_valid=valid, threshold=threshold, scenario=scenario)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mse 25883.152202387362 / mse base 1657410.707915358 : ratio 0.015616619392390932 mean ratio 0.015616619392390932 : p_ratio_pred 0.016369399630978852 fp_ratio_pred 0.16029933044505712\n",
            "mse 36165.90686542749 / mse base 1105614.3590499812 : ratio 0.03271114070597246 mean ratio 0.02245692947547668 : p_ratio_pred 0.01744117299278704 fp_ratio_pred 0.16266246553761324\n",
            "mse 145347.45452372852 / mse base 1365189.0073213824 : ratio 0.10646690952259619 mean ratio 0.05023879814841666 : p_ratio_pred 0.016522667461145044 fp_ratio_pred 0.15813312327688067\n",
            "mse 95298.75082835174 / mse base 915765.1153817634 : ratio 0.10406462227885113 mean ratio 0.06001120405887118 : p_ratio_pred 0.015926275992438562 fp_ratio_pred 0.1577392674281213\n",
            "mse 18663.64061478237 / mse base 1293528.7919238745 : ratio 0.014428469417386377 mean ratio 0.05070745566997029 : p_ratio_pred 0.016924074006138646 fp_ratio_pred 0.1636471051595116\n",
            "VALIDATION: mse 7320.939172447348 / mse base 1612787.2127774516 : ratio 0.004539308790674027\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.019245743729752074 : fp 0.07529168029658707 fp_pred 0.08346963253734598\n",
            "SUBMISSION: ratio * mse base: 0.05070745566997029 * 1894213.902757539 = 96050.76750351932 : p_pred 0.013767987891546363 fp_pred 0.15458342656821064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bPLsrbKOrQk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission[['invoice', 'total_return']].to_csv('submission_20200408_xgboost_hyperopt_eli.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QvbESbFCX8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRkoEwUA4XHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTeMvQKL4XK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_Tz04Q8Cog2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhoAEJck68tC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxEFGtVv68vy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANJfMwPeKYSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model #1\n",
        "\n",
        "def run_model_v2(model, feats, data, data_to_predict=None, data_valid=None, threshold=0.02, scenario={'opt': '3', 'fun': np.mean}):\n",
        "#     data = train.copy()\n",
        "#     data_test = test.copy()\n",
        "\n",
        "    X_invoice = data[['invoice', 'is_canceled']].drop_duplicates().reset_index(drop=True)\n",
        "    \n",
        "    scores = []\n",
        "    ratio_upper = 0\n",
        "    ratio_lower = 0\n",
        "    preditions = []\n",
        "    valid_preditions = []\n",
        "    \n",
        "    skf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
        "    for train_invoice_index, test_invoice_index in skf.split(X_invoice[['invoice']], X_invoice['is_canceled'] == True):\n",
        "        train_invoice_list = list(X_invoice.iloc[train_invoice_index].invoice)\n",
        "        test_invoice_list = list(X_invoice.iloc[test_invoice_index].invoice)\n",
        "\n",
        "        df_train, df_test = data[data.invoice.isin(train_invoice_list)], data[data.invoice.isin(test_invoice_list)]\n",
        "\n",
        "        X_train, X_test = df_train[feats], df_test[feats]\n",
        "        y_train, y_test = df_train['is_canceled'], df_test['is_canceled']\n",
        "\n",
        "        # class weights\n",
        "        class_weights = list(class_weight.compute_class_weight('balanced',\n",
        "                                                               np.unique(df_train['is_canceled']),\n",
        "                                                               df_train['is_canceled']))\n",
        "\n",
        "        w_array = np.ones(y_train.shape[0], dtype = 'float')\n",
        "        for i, val in enumerate(y_train):\n",
        "            w_array[i] = class_weights[val-1]\n",
        "\n",
        "        # model fit\n",
        "        \n",
        "        model.fit(X_train.values, y_train, eval_metric=[\"auc\",\"error\",\"logloss\"], sample_weight=w_array)\n",
        "\n",
        "#         tmp = df_train.copy()[['invoice', 'invoice_price_total', 'is_canceled']].drop_duplicates()\n",
        "#         mse_score_max = sum(tmp.invoice_price_total * tmp.invoice_price_total) / (len(tmp)-1)\n",
        "#         orders_train = df_train.copy()    \n",
        "#         orders_train['is_canceled_pred_1'] = model.predict(X_train.values) # 0,1\n",
        "#         orders_train['is_canceled_pred_2'] = model.predict_proba(X_train.values)[:, 1] # probrabilities\n",
        "#         orders_train['is_canceled_pred_3'] = orders_train['is_canceled_pred_2']*orders_train['price_total']/orders_train['invoice_price_total'] # probabilities weightedby price\n",
        "#         tmp = pd.merge(tmp, orders_train.groupby('invoice').agg(is_canceled_pred = ('is_canceled_pred_' + str(scenario['opt']), scenario['fun'])).reset_index(), how='left', on=['invoice'])            \n",
        "#         tmp['total_return'] = tmp['is_canceled'] * tmp['invoice_price_total']\n",
        "#         tmp['total_return_pred'] = (tmp['is_canceled_pred'] > threshold) * tmp['invoice_price_total']        \n",
        "#         mse_score = mse(tmp['total_return'], tmp['total_return_pred'])\n",
        "#         print('train set ratio: {}'.format(res_mse/res_mse_base))\n",
        "    \n",
        "        tmp = df_test.copy()[['invoice', 'invoice_price_total', 'is_canceled']].drop_duplicates()\n",
        "        mse_score_max = sum(tmp.invoice_price_total * tmp.invoice_price_total) / (len(tmp)-1)\n",
        "        ratio_lower += mse_score_max\n",
        "    \n",
        "        orders_test = df_test.copy()    \n",
        "        orders_test['is_canceled_pred_1'] = model.predict(X_test.values) # 0,1\n",
        "        orders_test['is_canceled_pred_2'] = model.predict_proba(X_test.values)[:, 1] # probrabilities\n",
        "        orders_test['is_canceled_pred_3'] = orders_test['is_canceled_pred_2']*orders_test['price_total']/orders_test['invoice_price_total'] # probabilities weightedby price\n",
        "        \n",
        "        p_ratio_pred = sum(orders_test['is_canceled_pred_' + str(scenario['opt'])] > threshold)/len(orders_test)\n",
        "\n",
        "        tmp = pd.merge(tmp, orders_test.groupby('invoice').agg(is_canceled_pred = ('is_canceled_pred_' + str(scenario['opt']), scenario['fun'])).reset_index(), how='left', on=['invoice'])            \n",
        "        tmp['total_return'] = tmp['is_canceled'] * tmp['invoice_price_total']\n",
        "        tmp['total_return_pred'] = (tmp['is_canceled_pred'] > threshold) * tmp['invoice_price_total']        \n",
        "        mse_score = mse(tmp['total_return'], tmp['total_return_pred'])\n",
        "        ratio_upper += mse_score\n",
        "\n",
        "        fp_ratio_pred = sum(tmp['is_canceled_pred'] > threshold)/len(tmp)\n",
        "        \n",
        "        print('mse {} / mse base {} : ratio {} mean ratio {} : p_ratio_pred {} fp_ratio_pred {}'.format(mse_score, mse_score_max, mse_score/mse_score_max, ratio_upper/ratio_lower, p_ratio_pred, fp_ratio_pred))\n",
        "        \n",
        "        scores += [mse_score/mse_score_max]\n",
        "\n",
        "        if data_valid is not None:\n",
        "            data_valid['is_canceled_pred_1'] = model.predict(data_valid[feats].values) # 0,1\n",
        "            data_valid['is_canceled_pred_2'] = model.predict_proba(data_valid[feats].values)[:, 1] # probrabilities\n",
        "            data_valid['is_canceled_pred_3'] = data_valid['is_canceled_pred_2']*data_valid['price_total']/data_valid['invoice_price_total'] # probabilities weightedby price\n",
        "            valid_preditions += [data_valid.copy()[['invoice', 'is_canceled_pred_' + str(scenario['opt'])]].rename(columns={'is_canceled_pred_' + str(scenario['opt']): 'is_canceled_pred'})]\n",
        "\n",
        "        if data_to_predict is not None:\n",
        "            data_to_predict['is_canceled_pred_1'] = model.predict(data_to_predict[feats].values) # 0,1\n",
        "            data_to_predict['is_canceled_pred_2'] = model.predict_proba(data_to_predict[feats].values)[:, 1] # probrabilities\n",
        "            data_to_predict['is_canceled_pred_3'] = data_to_predict['is_canceled_pred_2']*data_to_predict['price_total']/data_to_predict['invoice_price_total'] # probabilities weightedby price\n",
        "            preditions += [data_to_predict.copy()[['invoice', 'is_canceled_pred_' + str(scenario['opt'])]].rename(columns={'is_canceled_pred_' + str(scenario['opt']): 'is_canceled_pred'})]\n",
        "\n",
        "    scores_validation = None\n",
        "    if data_valid is not None:\n",
        "      w1 = 1/scores[0]\n",
        "      w2 = 1/scores[1]\n",
        "      w3 = 1/scores[2]\n",
        "      w4 = 1/scores[3]\n",
        "      w5 = 1/scores[4]\n",
        "      w = w1+w2+w3+w4+w5\n",
        "      w1 = w1/w\n",
        "      w2 = w2/w\n",
        "      w3 = w3/w\n",
        "      w4 = w4/w\n",
        "      w5 = w5/w\n",
        "\n",
        "      tmp = data_valid.copy()[['invoice', 'invoice_price_total']].drop_duplicates()\n",
        "      mse_score_max = sum(tmp.invoice_price_total * tmp.invoice_price_total) / (len(tmp)-1)\n",
        "\n",
        "      tmp = data_valid.copy()[['invoice', 'description', 'invoice_price_total', 'is_canceled']]\n",
        "      is_false = list(tmp[(tmp.description == 'adjust bad debt')].invoice.unique()) + [30477]\n",
        "      is_true  = list(tmp[(tmp.description == 'amazon fee')].invoice.unique())\n",
        "   \n",
        "      tmp['is_canceled_pred'] = valid_preditions[0]['is_canceled_pred']*w1 + valid_preditions[1]['is_canceled_pred']*w2 + valid_preditions[2]['is_canceled_pred']*w3 + valid_preditions[3]['is_canceled_pred']*w4 + valid_preditions[4]['is_canceled_pred']*w5\n",
        "\n",
        "      p_ratio = sum(tmp['is_canceled'] > threshold)/len(tmp)\n",
        "      p_ratio_pred = sum(tmp['is_canceled_pred'] > threshold)/len(tmp)\n",
        "\n",
        "      tmp = tmp.groupby('invoice').agg(is_canceled_pred = ('is_canceled_pred', scenario['fun']),\n",
        "                                       is_canceled = ('is_canceled', np.mean),\n",
        "                                       invoice_price_total = ('invoice_price_total', np.mean)).reset_index()\n",
        "        \n",
        "      tmp['total_return'] = tmp['is_canceled'] * tmp['invoice_price_total']\n",
        "\n",
        "      fp_ratio = sum(tmp['is_canceled'] > threshold)/len(tmp)\n",
        "      fp_ratio_pred = sum(tmp['is_canceled_pred'] > threshold)/len(tmp)\n",
        "\n",
        "      tmp['is_canceled_pred'] = tmp.apply(lambda x: 0 if x['invoice'] in is_false else x['is_canceled_pred'], axis=1)\n",
        "      tmp['is_canceled_pred'] = tmp.apply(lambda x: 1 if x['invoice'] in is_true else x['is_canceled_pred'], axis=1)\n",
        "\n",
        "      tmp['total_return_pred'] = (tmp['is_canceled_pred'] > threshold) * tmp['invoice_price_total']        \n",
        "      mse_score = mse(tmp['total_return'], tmp['total_return_pred'])\n",
        "  \n",
        "      scores_validation = mse_score/mse_score_max\n",
        "\n",
        "      print('VALIDATION: mse {} / mse base {} : ratio {}'.format(mse_score, mse_score_max, scores_validation))\n",
        "      print('VALIDATION: p {} p_pred {} : fp {} fp_pred {}'.format(p_ratio, p_ratio_pred, fp_ratio, fp_ratio_pred))\n",
        "\n",
        "    submission = None\n",
        "    if data_to_predict is not None:\n",
        "      w1 = 1/scores[0]\n",
        "      w2 = 1/scores[1]\n",
        "      w3 = 1/scores[2]\n",
        "      w4 = 1/scores[3]\n",
        "      w5 = 1/scores[4]\n",
        "      w = w1+w2+w3+w4+w5\n",
        "      w1 = w1/w\n",
        "      w2 = w2/w\n",
        "      w3 = w3/w\n",
        "      w4 = w4/w\n",
        "      w5 = w5/w\n",
        "\n",
        "      tmp = data_to_predict.copy()[['invoice', 'invoice_price_total']].drop_duplicates()\n",
        "      mse_score_max = sum(tmp.invoice_price_total * tmp.invoice_price_total) / (len(tmp)-1)\n",
        "  \n",
        "      tmp = data_to_predict.copy()[['invoice', 'description', 'invoice_price_total']].drop_duplicates()\n",
        "      is_false = list(tmp[(tmp.description == 'adjust bad debt')].invoice.unique()) + [30477]\n",
        "      is_true  = list(tmp[(tmp.description == 'amazon fee')].invoice.unique())\n",
        "   \n",
        "      tmp['is_canceled_pred'] = preditions[0]['is_canceled_pred']*w1 + preditions[1]['is_canceled_pred']*w2 + preditions[2]['is_canceled_pred']*w3 + preditions[3]['is_canceled_pred']*w4 + preditions[4]['is_canceled_pred']*w5\n",
        "      p_ratio_pred = sum(tmp['is_canceled_pred'] > threshold)/len(tmp)\n",
        "      \n",
        "      tmp = tmp.groupby('invoice').agg(is_canceled_pred = ('is_canceled_pred', scenario['fun']),\n",
        "                                       invoice_price_total = ('invoice_price_total', np.mean)).reset_index()\n",
        "\n",
        "      fp_ratio_pred = sum(tmp['is_canceled_pred'] > threshold)/len(tmp)\n",
        "\n",
        "      tmp['is_canceled_pred'] = tmp.apply(lambda x: 0 if x['invoice'] in is_false else x['is_canceled_pred'], axis=1)\n",
        "      tmp['is_canceled_pred'] = tmp.apply(lambda x: 1 if x['invoice'] in is_true else x['is_canceled_pred'], axis=1)\n",
        "\n",
        "      tmp['total_return_pred'] = (tmp['is_canceled_pred'] > threshold) * tmp['invoice_price_total']        \n",
        "\n",
        "      submission = tmp.copy()\n",
        "      submission = submission.rename(columns={'total_return_pred': 'total_return'})\n",
        "\n",
        "      print('SUBMISSION: ratio * mse base: {} * {} = {} : p_pred {} fp_pred {}'.format(ratio_upper/ratio_lower, mse_score_max, ratio_upper/ratio_lower*mse_score_max, p_ratio_pred, fp_ratio_pred))\n",
        "\n",
        "    return scores, ratio_upper/ratio_lower, scores_validation, submission"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIG8H-0EYH4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsQwBk6JYPIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKsqRlyOYPL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o-B8TyjYPNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL5If2m9YG54",
        "colab_type": "code",
        "outputId": "4835b569-314b-4bc6-f766-01b8d6eb45cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        }
      },
      "source": [
        "best = {'model': {'bagging_freq': 10, 'bagging_seed': 2020, 'boost_from_average': False, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.7207837526465946, 'data_random_seed': 2020, 'drop_seed': 2020, 'feature_fraction_seed': 2020, 'is_unbalance': True, 'learning_rate': 0.19565655054976303, 'max_bin': 150, 'max_depth': 12, 'metric': 'auc', 'min_child_samples': 260.0, 'min_data_in_leaf': 8, 'num_leaves': 180, 'objective': 'binary', 'reg_alpha': 0.9141189048912121, 'reg_lambda': 0.28623237458465467, 'save_binary': True, 'seed': 2020, 'verbose': 1}, 'threshold': 0.034}\n",
        "\n",
        "model = lgb.LGBMClassifier(**best['model'])\n",
        "\n",
        "feats = get_feats(train, out)\n",
        "\n",
        "X = train[feats].values\n",
        "y = train['is_canceled'].values\n",
        "\n",
        "# class weights\n",
        "class_weights = list(class_weight.compute_class_weight('balanced',\n",
        "                                                       np.unique(train['is_canceled']),\n",
        "                                                       train['is_canceled']))\n",
        "w_array = np.ones(y.shape[0], dtype = 'float')\n",
        "for i, val in enumerate(y):\n",
        "    w_array[i] = class_weights[val-1]\n",
        "\n",
        "# model fit\n",
        "model.fit(X, y, eval_metric=[\"auc\",\"error\",\"logloss\"], sample_weight=w_array)\n",
        "\n",
        "imp = PermutationImportance(model, random_state=0).fit(X, y)\n",
        "eli5.show_weights(imp, feature_names=feats, top=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0129\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cnt_customer_cancel_log\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 83.76%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0095\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quantity_sum_log\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 91.46%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0038\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                price_unit_sum_log\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 92.99%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0029\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cnt_product_cancel_2\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.44%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0016\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                invoice_price_total_log\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.56%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0015\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cnt_customer_not_cancel\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.05%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                invoice_date_min\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.15%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cnt_product_stock_cancel_2_log\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.73%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0006\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                customer_id\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.65%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quantity_min\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.92%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0002\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                price_unit_min\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.02%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0002\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                invoice_date_h\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.12%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cnt_product_cancel\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.33%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                price_unit_max\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.37%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                invoice\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.59%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                price_total_log\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.61%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                invoice_date_d\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.63%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                invoice_date_m\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.63%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quantity_mean\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.75%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cnt_product_stock_cancel_log\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.75%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                invoice_date_dow\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.80%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quantity_median\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.81%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                price_unit_median\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.85%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                price_unit_mean\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.87%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                country_cat\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.89%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                stock_code\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.93%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                price_cheap_exp_median\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.94%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cnt_customer_orders\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.97%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                price_cheap_exp_mean\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.97%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                stock_code_2\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.98%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cnt_product_orders\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.98%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cat_pack\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.98%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0000\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cnt_product_orders_2\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cat_craft\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cat_felt\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cat_bottle\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quantity_log\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cat_glass\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cat_water\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cat_car\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cat_case\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cat_hot\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cat_love\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                invoice_date_y\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                price_unit\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cat_mat\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cat_metal\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cat_paper\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cnt_product_stock_not_cancel_2_log\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                cat_christmas\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
              "                    <i>&hellip; 10 more &hellip;</i>\n",
              "                </td>\n",
              "            </tr>\n",
              "        \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOlg9eiVKTNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwY2fK_9LYFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feats_eli = ['cnt_customer_cancel_log','quantity_sum_log','price_unit_sum_log','cnt_product_cancel_2','invoice_price_total_log','cnt_customer_not_cancel','invoice_date_min','cnt_product_stock_cancel_2_log','customer_id','quantity_min','price_unit_min','invoice_date_h','cnt_product_cancel','price_unit_max','invoice','price_total_log','invoice_date_d','invoice_date_m','quantity_mean','cnt_product_stock_cancel_log','invoice_date_dow','quantity_median','price_unit_median','price_unit_mean','country_cat','stock_code','price_cheap_exp_median','cnt_customer_orders','price_cheap_exp_mean','stock_code_2','cnt_product_orders','cat_pack','cnt_product_orders_2',]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66VYAAwrYbbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1hrHC-WLYIU",
        "colab_type": "code",
        "outputId": "67804e85-aa9b-44f1-f1df-b9ceb9addc51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        }
      },
      "source": [
        "# hyperopt\n",
        "# feats = get_feats(train, out)\n",
        "feats = feats_eli\n",
        "\n",
        "def obj_func(params):\n",
        "  print(\"Training with params: \")\n",
        "  print(params)\n",
        "\n",
        "  scores, ratio, scores_validation, submission = run_model_v2(lgb.LGBMClassifier(**params['model']), feats, train, data_valid=valid, threshold=params['threshold'], scenario={'opt': '3', 'fun': np.mean})\n",
        "  print('MSE: {} ({}) - {} + {}'.format(np.abs(np.mean(scores)), np.std(scores), ratio, scores_validation))\n",
        "  print('---------------- \\n')\n",
        "\n",
        "  return {'loss': scores_validation, 'status': STATUS_OK}\n",
        "\n",
        "# space\n",
        "f_params = {'model': {\n",
        "    'class_weight': hp.choice('class_weight', [None, 'balanced']),\n",
        "    # 'boosting_type': hp.choice('boosting_type', \n",
        "    #                            [{'boosting_type': 'gbdt', \n",
        "    #                                 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n",
        "    #                              {'boosting_type': 'dart', \n",
        "    #                                  'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n",
        "    #                              {'boosting_type': 'goss'}]),\n",
        "    'num_leaves': hp.choice('num_leaves', range(30, 200, 10)),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
        "    # 'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000, dtype=int),\n",
        "    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0),\n",
        "\n",
        "    'max_bin': hp.choice('max_bin', range(50, 200, 10)),\n",
        "    'min_data_in_leaf': hp.choice('min_data_in_leaf', range(5, 30, 1)),\n",
        "    # 'min_sum_hessian_in_leaf': 0.00245,\n",
        "    # 'bagging_fraction': 1.0,\n",
        "    'bagging_freq': hp.choice('bagging_freq', range(1, 15, 1)),\n",
        "    # 'feature_fraction': 0.05,\n",
        "    # 'lambda_l1': 4.972,\n",
        "    # 'lambda_l2': 2.276,\n",
        "    # 'min_gain_to_split': 0.65,\n",
        "    'max_depth': hp.choice('max_depth', range(1, 16, 1)),\n",
        "\n",
        "    'save_binary': True,\n",
        "    'seed': 2020,\n",
        "    'feature_fraction_seed': 2020,\n",
        "    'bagging_seed': 2020,\n",
        "    'drop_seed': 2020,\n",
        "    'data_random_seed': 2020,\n",
        "    'objective': 'binary',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'verbose': 1,\n",
        "    'metric': \"auc\",\n",
        "    'is_unbalance': True,\n",
        "    'boost_from_average': False,\n",
        "},\n",
        "    'threshold': hp.quniform('threshold', 0.1, 0.25, 0.005)\n",
        "}\n",
        "\n",
        "# run\n",
        "best = fmin(obj_func, f_params, algo=tpe.suggest, max_evals=50, return_argmin=False)\n",
        "\n",
        "print('---------------- \\n')\n",
        "\n",
        "best"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training with params: \n",
            "{'model': {'bagging_freq': 10, 'bagging_seed': 2020, 'boost_from_average': False, 'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.700873410133455, 'data_random_seed': 2020, 'drop_seed': 2020, 'feature_fraction_seed': 2020, 'is_unbalance': True, 'learning_rate': 0.09928038996568483, 'max_bin': 80, 'max_depth': 5, 'metric': 'auc', 'min_child_samples': 365.0, 'min_data_in_leaf': 12, 'num_leaves': 60, 'objective': 'binary', 'reg_alpha': 0.14054543315286472, 'reg_lambda': 0.171761841288958, 'save_binary': True, 'seed': 2020, 'verbose': 1}, 'threshold': 0.14}\n",
            "  0%|          | 0/50 [00:00<?, ?it/s, best loss: ?]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-7f20fa38ec22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'---------------- \\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    405\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[1;32m    406\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    225\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                         \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    842\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 844\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-7f20fa38ec22>\u001b[0m in \u001b[0;36mobj_func\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_valid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'threshold'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscenario\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'opt'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fun'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MSE: {} ({}) - {} + {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'---------------- \\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'run_model_v2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2y416yKNeiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "with open('best_2.json', 'w') as f:\n",
        "  f.write(json.dumps(best))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5RElVo6X3ql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best = \\\n",
        "{'model': {'bagging_freq': 5,\n",
        "  'bagging_seed': 2020,\n",
        "  'boost_from_average': False,\n",
        "  'boosting_type': 'gbdt',\n",
        "  'class_weight': None,\n",
        "  'colsample_bytree': 0.701053176860787,\n",
        "  'data_random_seed': 2020,\n",
        "  'drop_seed': 2020,\n",
        "  'feature_fraction_seed': 2020,\n",
        "  'is_unbalance': True,\n",
        "  'learning_rate': 0.12771712520652634,\n",
        "  'max_bin': 170,\n",
        "  'max_depth': 10,\n",
        "  'metric': 'auc',\n",
        "  'min_child_samples': 335.0,\n",
        "  'min_data_in_leaf': 26,\n",
        "  'num_leaves': 150,\n",
        "  'objective': 'binary',\n",
        "  'reg_alpha': 0.6456603541982964,\n",
        "  'reg_lambda': 0.2628732832617849,\n",
        "  'save_binary': True,\n",
        "  'seed': 2020,\n",
        "  'verbose': 1},\n",
        " 'threshold': 0.12}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8Bi_JW5X3tW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98yn1Qk-X3wL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cStmz06hX3za",
        "colab_type": "code",
        "outputId": "0139c258-1008-48ea-e4e0-fb9b4d948630",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "# model eli + best\n",
        "\n",
        "model = lgb.LGBMClassifier(**best['model'])\n",
        "\n",
        "feats = feats_eli\n",
        "\n",
        "threshold = best['threshold']\n",
        "\n",
        "scenario={\n",
        "    'opt': '3', \n",
        "    'fun': np.mean\n",
        "}\n",
        "\n",
        "### run\n",
        "\n",
        "scores, ratio, scores_validation, submission = run_model_v2(model, feats, train, data_to_predict=test, data_valid=valid, threshold=threshold, scenario=scenario)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mse 22107.687202022273 / mse base 1657410.707915358 : ratio 0.01333868973842257 mean ratio 0.01333868973842257 : p_ratio_pred 0.013093154184605195 fp_ratio_pred 0.15478534856242615\n",
            "mse 35549.59729100755 / mse base 1105614.3590499812 : ratio 0.032153704408790576 mean ratio 0.02086744893572589 : p_ratio_pred 0.013680974340782784 fp_ratio_pred 0.15636077195746356\n",
            "mse 146755.0525319985 / mse base 1365189.0073213824 : ratio 0.10749797408634608 mean ratio 0.049515924646021885 : p_ratio_pred 0.013816475495307613 fp_ratio_pred 0.15419456478928711\n",
            "mse 92002.25449555025 / mse base 915765.1153817634 : ratio 0.10046490410065077 mean ratio 0.0587660218994798 : p_ratio_pred 0.013445179584120982 fp_ratio_pred 0.15833005120126034\n",
            "mse 27355.132775675644 / mse base 1293528.7919238745 : ratio 0.02114767985565297 mean ratio 0.051087860597045585 : p_ratio_pred 0.014111547256563581 fp_ratio_pred 0.16010240252067742\n",
            "VALIDATION: mse 33176.38174998268 / mse base 1612787.2127774516 : ratio 0.02057083630570717\n",
            "VALIDATION: p 0.019139997885083106 p_pred 0.014131490151216558 : fp 0.07529168029658707 fp_pred 0.07043942863373678\n",
            "SUBMISSION: ratio * mse base: 0.051087860597045585 * 1894213.902757539 = 96771.33580506282 : p_pred 0.010295258802830429 fp_pred 0.1356008055493399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmdfCZvLX32c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFgaXc1yo8-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission[['invoice', 'total_return']].to_csv('submission_20200408_lgbm_hyperopt_eli_final.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExyfhjSWo9BD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mse 35913.58464171226 / mse base 1413979.3221247324 : ratio 0.025398946137165777 mean ratio 0.025398946137165777 : p_ratio_pred 0.01960060082243727 fp_ratio_pred 0.18302073050345508\n",
        "mse 37601.65312482367 / mse base 1833752.1432910159 : ratio 0.02050530834409299 mean ratio 0.022635873239330487 : p_ratio_pred 0.018585435185854354 fp_ratio_pred 0.1788746298124383\n",
        "mse 57256.690000476374 / mse base 1317959.2996501562 : ratio 0.043443443219889105 mean ratio 0.028642309454596764 : p_ratio_pred 0.0184421256976462 fp_ratio_pred 0.1796998420221169\n",
        "mse 46602.30779920009 / mse base 825381.321367404 : ratio 0.05646154885355819 mean ratio 0.03290147724282459 : p_ratio_pred 0.019125521578269248 fp_ratio_pred 0.18305687203791468\n",
        "mse 169852.20341477386 / mse base 939887.3627723363 : ratio 0.18071548798546427 mean ratio 0.054845784713492884 : p_ratio_pred 0.01881454236808601 fp_ratio_pred 0.1779225908372828\n",
        "VALIDATION: mse 22772.978063982544 / mse base 1585230.1557363835 : ratio 0.014365723476540769\n",
        "VALIDATION: p 0.019322649798602234 p_pred 0.02030320217644175 : fp 0.07657706481682203 fp_pred 0.09299804899197919\n",
        "SUBMISSION: ratio * mse base: 0.054845784713492884 * 1894213.902757539 = 103889.64791194513 : p_pred 0.015876979340335134 fp_pred 0.1712538226299694"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH3ucUDto9EQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLPrjobmo9Gw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nmkrgeqo9Kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAo6s9SLI12K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}